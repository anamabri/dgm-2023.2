{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4959f9e7-c299-4806-bc1e-0af7bfc2c023",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8da9e354-8014-49ae-9dee-643e6fd0981a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-11-10 18:27:24.176463: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-10 18:27:24.176492: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-10 18:27:24.176520: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-10 18:27:24.183628: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow not install, you could not use those pipelines\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0) # Set for our testing purposes, please do not change!\n",
    "\n",
    "from braindecode.datasets import MOABBDataset\n",
    "from braindecode.preprocessing import (\n",
    "    exponential_moving_standardize, preprocess, Preprocessor)\n",
    "from braindecode.preprocessing import \\\n",
    "    create_windows_from_events, create_fixed_length_windows\n",
    "from sklearn.preprocessing import scale as standard_scale\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28), nrow=5, show=True):\n",
    "    '''\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\n",
    "    size per image, plots and prints the images in an uniform grid.\n",
    "    '''\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b42237e-d481-482a-9765-41ab1e15cbde",
   "metadata": {},
   "source": [
    "# Creating function to get EEG Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4134d512-81b7-4067-b8f8-eddcbb13def3",
   "metadata": {},
   "source": [
    "## Preprocess Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f3c27fe-273a-4046-b51a-4965537415ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(\n",
    "    dataset,\n",
    "    low_cut_hz = 4.,   # low cut frequency for filtering\n",
    "    high_cut_hz = 38., # high cut frequency for filtering\n",
    "    newfreq = 100, # Paramater for resampling\n",
    "    # factor = 1e6, # Parameter for scaling\n",
    "    ):\n",
    "\n",
    "    preprocessors = [\n",
    "        Preprocessor('pick_types', eeg=True, meg=False, stim=False),  # Keep EEG sensors\n",
    "        # Preprocessor(lambda data: np.multiply(data, factor)),  # Convert from V to uV\n",
    "        Preprocessor(\"resample\", sfreq=newfreq), # Resampling\n",
    "        Preprocessor('filter', l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter\n",
    "        Preprocessor(\"set_eeg_reference\", ref_channels=\"average\", ch_type=\"eeg\") # Common Average Reference\n",
    "        # Preprocessor()\n",
    "    ]\n",
    "    \n",
    "    # Transform the data\n",
    "    # return preprocess(dataset, preprocessors, n_jobs = -1)\n",
    "    return preprocess(dataset, preprocessors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5754a92-a3d8-483e-b757-64be8e64d45a",
   "metadata": {},
   "source": [
    "## Get Windows from Dataset function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee26c93-78cb-4d5e-86d3-ae876e0a1bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows(\n",
    "        dataset, \n",
    "        trial_start_offset_samples=0,\n",
    "        trial_stop_offset_samples=100,\n",
    "        window_size_samples=400,\n",
    "        window_stride_samples=100,\n",
    "        preload=True,\n",
    "        # mapping = {'left_hand': 0, 'right_hand': 1},\n",
    "        picks = ['C3', 'Cz', 'C4']\n",
    "        ):\n",
    "    \n",
    "    windows_dataset = create_windows_from_events(\n",
    "        dataset,\n",
    "        trial_start_offset_samples = trial_start_offset_samples,\n",
    "        trial_stop_offset_samples  = trial_stop_offset_samples,\n",
    "        window_size_samples        = window_size_samples,\n",
    "        window_stride_samples      = window_stride_samples,\n",
    "        preload                    = True,\n",
    "        # mapping = {'left_hand': 0, 'right_hand': 1},\n",
    "        # picks                      = picks\n",
    "        )\n",
    "\n",
    "    preprocess(windows_dataset, [Preprocessor(standard_scale, channel_wise=True)]) ## Standard Scale window\n",
    "    \n",
    "    return windows_dataset\n",
    "\n",
    "\n",
    "def get_tensors_from_windows(windows_dataset):\n",
    "    windows_list = []\n",
    "    labels_list = []\n",
    "    n_runs = len(windows_dataset.datasets)\n",
    "    for i in range(n_runs):\n",
    "        windows_list.append(windows_dataset.datasets[i].windows.get_data())\n",
    "        labels_list.append(windows_dataset.datasets[i].y)\n",
    "        \n",
    "    stacked_tensor = np.concatenate(windows_list, axis=0)\n",
    "    stacked_labels = np.concatenate(labels_list, axis=0)\n",
    "    \n",
    "    del windows_list,labels_list\n",
    "    \n",
    "    return stacked_tensor, stacked_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f067c7e2-f452-434d-97d6-8fd6b8850722",
   "metadata": {},
   "source": [
    "# Creating EEG Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9691fcb9-4f26-4aad-8941-d70869e98c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG(Dataset):\n",
    "\n",
    "    def __init__(self, subject_id = 3, dataset_name=\"BNCI2014_001\", transform = None):\n",
    "        \n",
    "        self.raw_dataset     = MOABBDataset(dataset_name = dataset_name, subject_ids=subject_id)\n",
    "        self.prepro_dataset  = preprocessor(self.raw_dataset)\n",
    "        self.windows_dataset = get_windows(self.prepro_dataset)\n",
    "        self.data            = get_tensors_from_windows(self.windows_dataset)\n",
    "        self.transform       = transform\n",
    "        self.classes         = self.windows_dataset.datasets[0].windows.event_id\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data[0].shape[0]\n",
    "\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        # sample = {'signal': torch.from_numpy(self.data[0])[idx], 'label': torch.from_numpy(self.data[1])[idx]}\n",
    "        \n",
    "        sample = (torch.from_numpy(np.expand_dims(self.data[0], axis = 1))[idx], torch.from_numpy(self.data[1])[idx])\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "657f4d24-f00a-4303-9f54-9de06874125a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n"
     ]
    }
   ],
   "source": [
    "my_eeg_data = EEG(subject_id=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f6779f-cf12-46eb-8f5d-7df3419484b6",
   "metadata": {},
   "source": [
    "# Creating CGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2949ab9c-6290-43c3-b673-123d8e1cc7ae",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f43155b5-54c5-4f88-a13a-a7710e3f24c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    '''\n",
    "    Generator Class\n",
    "    Values:\n",
    "        input_dim: the dimension of the input vector, a scalar\n",
    "        im_chan: the number of channels of the output eeg, a scalar\n",
    "        hidden_dim: the inner dimension, a scalar\n",
    "    '''\n",
    "    def __init__(self, input_dim=68, im_chan=1, hidden_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        # Build the neural network\n",
    "        self.gen = nn.Sequential(\n",
    "            #### For 3 channels\n",
    "            # self.make_gen_block(input_dim, hidden_dim * 4,      kernel_size = (1,60), stride = (1,1)),\n",
    "            # self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size = (1,60), stride = (1,1)),\n",
    "            # self.make_gen_block(hidden_dim * 2, hidden_dim,     kernel_size = (1,60), stride = (1,1)),\n",
    "            # self.make_gen_block(hidden_dim, im_chan,            kernel_size = (3,50), stride = (1,2), padding = (0,2), final_layer=True),\n",
    "            #### For 22 channels\n",
    "            self.make_gen_block(input_dim, hidden_dim * 4,      kernel_size = (3,60), stride = (1,1)),\n",
    "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size = (4,60), stride = (3,1)),\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim,     kernel_size = (3,60), stride = (2,1)),\n",
    "            self.make_gen_block(hidden_dim, im_chan,            kernel_size = (2,50), stride = (1,2), padding = (0,2), final_layer=True),\n",
    "        )\n",
    "\n",
    "    def make_gen_block(self, input_channels, output_channels, kernel_size, stride, padding = 0, final_layer=False):\n",
    "        '''\n",
    "        Function to return a sequence of operations corresponding to a generator block of DCGAN;\n",
    "        a transposed convolution, a batchnorm (except in the final layer), and an activation.\n",
    "        Parameters:\n",
    "            input_channels: how many channels the input feature representation has\n",
    "            output_channels: how many channels the output feature representation should have\n",
    "            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\n",
    "            stride: the stride of the convolution\n",
    "            final_layer: a boolean, true if it is the final layer and false otherwise \n",
    "                      (affects activation and batchnorm)\n",
    "        '''\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride, padding),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride, padding),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        '''\n",
    "        Function for completing a forward pass of the generator: Given a noise tensor, \n",
    "        returns generated images.\n",
    "        Parameters:\n",
    "            noise: a noise tensor with dimensions (n_samples, input_dim)\n",
    "        '''\n",
    "        x = noise.view(len(noise), self.input_dim, 1, 1)\n",
    "        return self.gen(x)\n",
    "\n",
    "def get_noise(n_samples, input_dim, device='cpu'):\n",
    "    '''\n",
    "    Function for creating noise vectors: Given the dimensions (n_samples, input_dim)\n",
    "    creates a tensor of that shape filled with random numbers from the normal distribution.\n",
    "    Parameters:\n",
    "        n_samples: the number of samples to generate, a scalar\n",
    "        input_dim: the dimension of the input vector, a scalar\n",
    "        device: the device type\n",
    "    '''\n",
    "    return torch.randn(n_samples, input_dim, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8fe5ac-5528-459c-949d-13847f7d5ae1",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db3e50e-82fe-45ee-913c-4388bead29fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    '''\n",
    "    Discriminator Class\n",
    "    Values:\n",
    "      im_chan: the number of channels of the output eeg, a scalar\n",
    "      hidden_dim: the inner dimension, a scalar\n",
    "    '''\n",
    "    def __init__(self, im_chan=5, hidden_dim=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            #### 3 Channels\n",
    "            # self.make_disc_block(im_chan, hidden_dim,        kernel_size = (1,50), stride = (2,4)),\n",
    "            # self.make_disc_block(hidden_dim, hidden_dim * 2, kernel_size = (1,50), stride = (2,4)),\n",
    "            # self.make_disc_block(hidden_dim * 2, 1,          kernel_size = (1,10), stride = (2,1), final_layer=True),\n",
    "            #### 22 Channels\n",
    "            self.make_disc_block(im_chan, hidden_dim,        kernel_size = (4,50), stride = (3,4)),\n",
    "            self.make_disc_block(hidden_dim, hidden_dim * 2, kernel_size = (3,50), stride = (2,4)),\n",
    "            self.make_disc_block(hidden_dim * 2, 1,          kernel_size = (3,10), stride = (1,1), final_layer=True),\n",
    "\n",
    "        )\n",
    "\n",
    "    def make_disc_block(self, input_channels, output_channels, kernel_size, stride, final_layer=False):\n",
    "        '''\n",
    "        Function to return a sequence of operations corresponding to a discriminator block of the DCGAN; \n",
    "        a convolution, a batchnorm (except in the final layer), and an activation (except in the final layer).\n",
    "        Parameters:\n",
    "            input_channels: how many channels the input feature representation has\n",
    "            output_channels: how many channels the output feature representation should have\n",
    "            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\n",
    "            stride: the stride of the convolution\n",
    "            final_layer: a boolean, true if it is the final layer and false otherwise \n",
    "                      (affects activation and batchnorm)\n",
    "        '''\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
    "            )\n",
    "\n",
    "    def forward(self, image):\n",
    "        '''\n",
    "        Function for completing a forward pass of the discriminator: Given an image tensor, \n",
    "        returns a 1-dimension tensor representing fake/real.\n",
    "        Parameters:\n",
    "            image: a flattened image tensor with dimension (im_chan)\n",
    "        '''\n",
    "        disc_pred = self.disc(image)\n",
    "        return disc_pred.view(len(disc_pred), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4600c7bf-18b2-4491-ab0b-2aad906fb1b2",
   "metadata": {},
   "source": [
    "## Class Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a965b463-2fa0-4e62-bfc1-122b7daee376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot_labels(labels, n_classes):\n",
    "    '''\n",
    "    Function for creating one-hot vectors for the labels, returns a tensor of shape (?, num_classes).\n",
    "    Parameters:\n",
    "        labels: tensor of labels from the dataloader, size (?)\n",
    "        n_classes: the total number of classes in the dataset, an integer scalar\n",
    "    '''\n",
    "    return F.one_hot(labels,n_classes)\n",
    "\n",
    "def combine_vectors(x, y):\n",
    "    '''\n",
    "    Function for combining two vectors with shapes (n_samples, ?) and (n_samples, ?).\n",
    "    Parameters:\n",
    "      x: (n_samples, ?) the first vector. \n",
    "        In this assignment, this will be the noise vector of shape (n_samples, z_dim), \n",
    "        but you shouldn't need to know the second dimension's size.\n",
    "      y: (n_samples, ?) the second vector.\n",
    "        Once again, in this assignment this will be the one-hot class vector \n",
    "        with the shape (n_samples, n_classes), but you shouldn't assume this in your code.\n",
    "    '''\n",
    "    combined = torch.cat((x.float(),y.float()), 1)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1193df6-7694-46be-890c-29f7c721f958",
   "metadata": {},
   "source": [
    "## Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c9d8dde-a8c9-4213-b908-049452ab3289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg_shape = (1, 3, 400)\n",
    "eeg_shape = my_eeg_data[0][0].shape\n",
    "n_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd92c6ff-782e-479d-adbd-cd9839430257",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "n_epochs = 100\n",
    "z_dim = 64\n",
    "display_step = 50\n",
    "batch_size = 100\n",
    "lr = 0.0002\n",
    "device = 'cuda'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b8efaf0-d4f6-4663-8afd-c0558f91e6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([100, 1, 22, 400]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "dataloader = DataLoader(my_eeg_data, batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "\n",
    "for i_batch, (signal,label) in enumerate(dataloader):\n",
    "    print(i_batch, signal.size(),\n",
    "      label.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21f522d0-4f13-45a0-8952-a5cc62e29e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_dimensions(z_dim, eeg_shape, n_classes):\n",
    "    '''\n",
    "    Function for getting the size of the conditional input dimensions \n",
    "    from z_dim, the image shape, and number of classes.\n",
    "    Parameters:\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        eeg_shape: the shape of each EEG data as (C, W, H), which is (1, 3, 400), that is, we choose 3 channels (3 electrodes)\n",
    "        n_classes: the total number of classes in the dataset, an integer scalar\n",
    "                (4 for EEG, that is 4 movements - tongue, left hand, right hand and feet)\n",
    "    Returns: \n",
    "        generator_input_dim: the input dimensionality of the conditional generator, \n",
    "                          which takes the noise and class vectors\n",
    "        discriminator_im_chan: the number of input channels to the discriminator\n",
    "                            (e.g. C x 3 x 400 for EEG)\n",
    "    '''\n",
    "    generator_input_dim = z_dim + n_classes\n",
    "    discriminator_im_chan = eeg_shape[0] + n_classes\n",
    "    return generator_input_dim, discriminator_im_chan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71d82a1b-122b-4d31-9af8-3991fc13944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_input_dim, discriminator_im_chan = get_input_dimensions(z_dim, eeg_shape, n_classes)\n",
    "\n",
    "gen = Generator(input_dim=generator_input_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "disc = Discriminator(im_chan=discriminator_im_chan).to(device)\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "gen = gen.apply(weights_init)\n",
    "disc = disc.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe5b3483-75e5-48cf-b938-a745eebf233d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(n_epochs):\n",
    "    \n",
    "\n",
    "    cur_step = 0\n",
    "    generator_losses = []\n",
    "    discriminator_losses = []\n",
    "\n",
    "    generator_loss_epoch = []\n",
    "    discriminator_loss_epoch = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for real, labels in tqdm(dataloader):\n",
    "            cur_batch_size = len(real)\n",
    "            # Flatten the batch of real images from the dataset\n",
    "            real = real.to(device)\n",
    "        \n",
    "            one_hot_labels = get_one_hot_labels(labels.to(device), n_classes)\n",
    "            eeg_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "            eeg_one_hot_labels = eeg_one_hot_labels.repeat(1, 1, eeg_shape[1], eeg_shape[2])\n",
    "        \n",
    "            ### Update discriminator ###\n",
    "            # Zero out the discriminator gradients\n",
    "            disc_opt.zero_grad()\n",
    "            # Get noise corresponding to the current batch_size \n",
    "            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "        \n",
    "            # Now we can get the eeg data from the generator\n",
    "            # Steps: 1) Combine the noise vectors and the one-hot labels for the generator\n",
    "            #        2) Generate the conditioned fake eeg\n",
    "            noise_and_labels = combine_vectors(fake_noise, one_hot_labels)\n",
    "            fake = gen(noise_and_labels)\n",
    "        \n",
    "            # Now we can get the predictions from the discriminator\n",
    "            # Steps: 1) Create the input for the discriminator\n",
    "            #           a) Combine the fake images with image_one_hot_labels, \n",
    "            #              remember to detach the generator (.detach()) so you do not backpropagate through it\n",
    "            #           b) Combine the real images with image_one_hot_labels\n",
    "            #        2) Get the discriminator's prediction on the fakes as disc_fake_pred\n",
    "            #        3) Get the discriminator's prediction on the reals as disc_real_pred\n",
    "            \n",
    "            fake_image_and_labels = combine_vectors(fake, eeg_one_hot_labels)\n",
    "            real_image_and_labels = combine_vectors(real, eeg_one_hot_labels)\n",
    "            disc_fake_pred = disc(fake_image_and_labels.detach())\n",
    "            disc_real_pred = disc(real_image_and_labels)\n",
    "        \n",
    "            disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
    "            disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
    "            disc_loss = (disc_fake_loss + disc_real_loss) / 2\n",
    "            disc_loss.backward(retain_graph=True)\n",
    "            disc_opt.step() \n",
    "        \n",
    "            # Keep track of the average discriminator loss\n",
    "            discriminator_losses += [disc_loss.item()]\n",
    "        \n",
    "            ### Update generator ###\n",
    "            # Zero out the generator gradients\n",
    "            gen_opt.zero_grad()\n",
    "        \n",
    "            fake_image_and_labels = combine_vectors(fake, eeg_one_hot_labels)\n",
    "            # This will error if you didn't concatenate your labels to your image correctly\n",
    "            disc_fake_pred = disc(fake_image_and_labels)\n",
    "            gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
    "            gen_loss.backward()\n",
    "            gen_opt.step()\n",
    "        \n",
    "            # Keep track of the generator losses\n",
    "            generator_losses += [gen_loss.item()]\n",
    "        \n",
    "            if cur_step % display_step == 0 and cur_step > 0:\n",
    "                gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
    "                disc_mean = sum(discriminator_losses[-display_step:]) / display_step\n",
    "                print(f\"Step {cur_step}: Generator loss: {gen_mean}, discriminator loss: {disc_mean}\")\n",
    "                step_bins = 20\n",
    "                x_axis = sorted([i * step_bins for i in range(len(generator_losses) // step_bins)] * step_bins)\n",
    "                num_examples = (len(generator_losses) // step_bins) * step_bins\n",
    "                plt.plot(\n",
    "                    range(num_examples // step_bins), \n",
    "                    torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                    label=\"Generator Loss\"\n",
    "                )\n",
    "                plt.plot(\n",
    "                    range(num_examples // step_bins), \n",
    "                    torch.Tensor(discriminator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                    label=\"Discriminator Loss\"\n",
    "                )\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "    \n",
    "            elif cur_step == 0:\n",
    "                pass# print(\"Congratulations! If you've gotten here, it's working. Please let this train until you're happy with how the generated numbers look, and then go on to the exploration!\")\n",
    "            cur_step += 1\n",
    "        generator_loss_epoch.append(gen_loss.item())\n",
    "        discriminator_loss_epoch.append(disc_loss.item())\n",
    "\n",
    "    return gen, generator_loss_epoch, discriminator_loss_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0767d5-d618-4a3f-8846-9f772c7229d9",
   "metadata": {},
   "source": [
    "## Plot the generator and discriminator loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb048785-1660-441c-90ef-61f003aa38e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:20<00:00,  1.71s/it]\n",
      "100%|██████████| 12/12 [00:20<00:00,  1.67s/it]\n",
      "100%|██████████| 12/12 [00:19<00:00,  1.66s/it]\n",
      "100%|██████████| 12/12 [00:20<00:00,  1.69s/it]\n",
      " 17%|█▋        | 2/12 [00:03<00:17,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50: Generator loss: 0.716711699962616, discriminator loss: 0.6520463573932648\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:20<00:00,  1.74s/it]\n",
      " 33%|███▎      | 4/12 [00:08<00:17,  2.23s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[0;32m----> 2\u001b[0m _, gen_loss, disc_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 67\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(n_epochs)\u001b[0m\n\u001b[1;32m     64\u001b[0m gen_opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Keep track of the generator losses\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m generator_losses \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[43mgen_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cur_step \u001b[38;5;241m%\u001b[39m display_step \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cur_step \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     70\u001b[0m     gen_mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(generator_losses[\u001b[38;5;241m-\u001b[39mdisplay_step:]) \u001b[38;5;241m/\u001b[39m display_step\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 500\n",
    "_, gen_loss, disc_loss = train(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deef6886-4124-42f2-8510-b9f8704f5155",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Os gráficos serão salvos dentro da pasta Testes_Finais/nome_da_pasta\n",
    "nome_da_pasta = \"arquitetura_gan\"\n",
    "nome_do_arquivo = \"nome_teste\"\n",
    "titulo = \"Titulo Teste\"\n",
    "\n",
    "path = \"Testes_Finais/\" + nome_da_pasta + \"/\" + nome_do_arquivo + \".png\"\n",
    "plt.plot(range(1,n_epochs+1), gen_loss, label=\"Generator Loss\")\n",
    "plt.plot(range(1,n_epochs+1), disc_loss,label=\"Discriminator Loss\"  )\n",
    "plt.xlabel(\"Número de Épocas\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(titulo)\n",
    "plt.legend()\n",
    "plt.savefig(path)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b55e2b-76e5-44ea-b700-f64118668c63",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4acec8-766b-46fa-a017-b73988f93bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate samples\n",
    "\n",
    "def generate_samples(label, n_samples, generator):\n",
    "    '''\n",
    "    Function for generating samples, once the generator has been trained\n",
    "        label: label of the movement to be sampled. See dictionary below\n",
    "        {'feet': 0, 'left_hand': 1, 'right_hand': 2, 'tongue': 3}\n",
    "        n_samples: number of samples to be generated\n",
    "        generator: the trained generator\n",
    "    '''\n",
    "\n",
    "    noise_4_gen = get_noise(n_samples, z_dim, device=device)\n",
    "    label = get_one_hot_labels(torch.Tensor([label]).long(), n_classes).repeat(n_samples,1)\n",
    "    \n",
    "    noise_and_labels = combine_vectors(noise_4_gen, label.to(device))\n",
    "    fake = gen(noise_and_labels)\n",
    "    return fake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c0ecd7-b5fc-405e-b468-35426d92e9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before you explore, you should put the generator\n",
    "# in eval mode, both in general and so that batch norm\n",
    "# doesn't cause you issues and is using its eval statistics\n",
    "gen = gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c50fd20-2b65-4def-9243-615e74a795a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remembering labels\n",
    "print(my_eeg_data.windows_dataset.datasets[0].windows.event_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7cd2bf-ea5e-4788-8567-9ff2be675e23",
   "metadata": {},
   "source": [
    "# Computing Dimensions for GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0034bb77-463b-4966-8a13-21467a558064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "def compute_dim_TransConv2D(Hin, \n",
    "                        kernel_size=1, \n",
    "                        stride=1,\n",
    "                        padding = 0,\n",
    "                        dilation = 1,\n",
    "                        output_padding = 0\n",
    "        \n",
    "        ):\n",
    "    return ((Hin - 1)*stride) - (2*padding)+ (dilation*(kernel_size - 1)) + output_padding + 1\n",
    "\n",
    "def compute_dim_Conv2D(Hin, \n",
    "                kernel_size=50, \n",
    "                stride=4,\n",
    "                padding = 0,\n",
    "                dilation = 1\n",
    "                ):\n",
    "    return floor( (Hin + (2*padding) - (dilation*(kernel_size-1)) -1)/(stride) + 1 ) \n",
    "\n",
    "## For EEG CG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6480acac-712f-40c9-8af6-2924d0be04bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dim_TransConv2D(\n",
    "    compute_dim_TransConv2D(\n",
    "        compute_dim_TransConv2D(\n",
    "            compute_dim_TransConv2D(1, kernel_size=3, stride = 1\n",
    "            ), kernel_size=4, stride = 3\n",
    "        ),kernel_size=3, stride = 2\n",
    "    ),kernel_size=2, stride = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f320dba-2371-4a36-beee-1bae4b7faa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dim_Conv2D(compute_dim_Conv2D(compute_dim_Conv2D(22, kernel_size = 4, stride = 3\n",
    "                                                        ) , kernel_size = 3, stride = 2\n",
    "                                     ), kernel_size = 3, stride = 1\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac39550-e485-4eca-8a14-02f069645cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.make_disc_block(im_chan, hidden_dim,        kernel_size = (1,50), stride = (2,4)),\n",
    "self.make_disc_block(hidden_dim, hidden_dim * 2, kernel_size = (1,50), stride = (2,4)),\n",
    "self.make_disc_block(hidden_dim * 2, 1,          kernel_size = (1,10), stride = (2,1), final_layer=True),\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
