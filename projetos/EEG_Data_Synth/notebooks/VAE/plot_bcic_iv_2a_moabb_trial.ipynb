{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Basic Brain Decoding on EEG Data\n",
    "\n",
    "This tutorial shows you how to train and test deep learning models with\n",
    "Braindecode in a classical EEG setting: you have trials of data with\n",
    "labels (e.g., Right Hand, Left Hand, etc.).\n",
    "   :depth: 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing the data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the data. In this tutorial, we load the BCI Competition\n",
    "IV 2a data [1]_ using braindecode's wrapper to load via\n",
    "[MOABB library](https://github.com/NeuroTechX/moabb)_ [2]_.\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>To load your own datasets either via mne or from\n",
    "   preprocessed X/y numpy arrays, see [MNE Dataset\n",
    "   Tutorial](./plot_mne_dataset_example.html)_ and [Numpy Dataset\n",
    "   Tutorial](./plot_custom_dataset_example.html)_.</p></div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 17:15:28.214830: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-17 17:15:28.214857: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-17 17:15:28.214881: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-17 17:15:28.221511: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow not install, you could not use those pipelines\n"
     ]
    }
   ],
   "source": [
    "from braindecode.datasets import MOABBDataset\n",
    "\n",
    "subject_id = 3\n",
    "dataset = MOABBDataset(dataset_name=\"BNCI2014_001\", subject_ids=[subject_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply preprocessing like bandpass filtering to our dataset. You\n",
    "can either apply functions provided by\n",
    "[mne.Raw](https://mne.tools/stable/generated/mne.io.Raw.html)_ or\n",
    "[mne.Epochs](https://mne.tools/0.11/generated/mne.Epochs.html#mne.Epochs)_\n",
    "or apply your own functions, either to the MNE object or the underlying\n",
    "numpy array.\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>Generally, braindecode prepocessing is directly applied to the loaded\n",
    "   data, and not applied on-the-fly as transformations, such as in\n",
    "   PyTorch-libraries like\n",
    "   [torchvision](https://pytorch.org/docs/stable/torchvision/index.html)_.</p></div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/braindecode/preprocessing/preprocess.py:55: UserWarning: Preprocessing choices with lambda functions cannot be saved.\n",
      "  warn('Preprocessing choices with lambda functions cannot be saved.')\n",
      "2023-11-17 17:15:46.152385: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-17 17:15:46.152427: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-17 17:15:46.152461: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-17 17:15:46.162806: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-17 17:15:46.471167: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-17 17:15:46.471210: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-17 17:15:46.471242: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-17 17:15:46.481285: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-17 17:15:46.709050: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-17 17:15:46.709425: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-17 17:15:46.709487: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-17 17:15:46.721522: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-17 17:15:47.054681: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-17 17:15:47.054726: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-17 17:15:47.054766: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-17 17:15:47.068739: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-17 17:15:47.073387: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-17 17:15:47.073475: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-17 17:15:47.073575: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-17 17:15:47.083334: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-17 17:15:47.138404: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-17 17:15:47.138553: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-17 17:15:47.138811: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-17 17:15:47.150264: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-17 17:15:47.216502: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-17 17:15:47.216632: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-17 17:15:47.216689: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-17 17:15:47.228503: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-17 17:15:47.321216: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-17 17:15:47.321634: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-17 17:15:47.321707: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-17 17:15:47.333453: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow not install, you could not use those pipelines\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Tensorflow not install, you could not use those pipelines\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Tensorflow not install, you could not use those pipelines\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow not install, you could not use those pipelines\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Tensorflow not install, you could not use those pipelines\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Tensorflow not install, you could not use those pipelines\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Tensorflow not install, you could not use those pipelines\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow not install, you could not use those pipelines\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "Filtering raw data in 1 contiguous segment\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<braindecode.datasets.moabb.MOABBDataset at 0x7f9b5075e8d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import multiply\n",
    "\n",
    "from braindecode.preprocessing import (Preprocessor,\n",
    "                                       exponential_moving_standardize,\n",
    "                                       preprocess)\n",
    "\n",
    "low_cut_hz = 4.  # low cut frequency for filtering\n",
    "high_cut_hz = 38.  # high cut frequency for filtering\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "# Factor to convert from V to uV\n",
    "factor = 1e6\n",
    "\n",
    "preprocessors = [\n",
    "    Preprocessor('pick_types', eeg=True, meg=False, stim=False),  # Keep EEG sensors\n",
    "    Preprocessor(lambda data: multiply(data, factor)),  # Convert from V to uV\n",
    "    Preprocessor('filter', l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter\n",
    "    Preprocessor(exponential_moving_standardize,  # Exponential moving standardization\n",
    "                 factor_new=factor_new, init_block_size=init_block_size)\n",
    "]\n",
    "\n",
    "# Transform the data\n",
    "preprocess(dataset, preprocessors, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Compute Windows\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extract compute windows from the signals, these will be the inputs\n",
    "to the deep networks during training. In the case of trialwise\n",
    "decoding, we just have to decide if we want to include some part\n",
    "before and/or after the trial. For our work with this dataset,\n",
    "it was often beneficial to also include the 500 ms before the trial.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n"
     ]
    }
   ],
   "source": [
    "from braindecode.preprocessing import create_windows_from_events\n",
    "\n",
    "trial_start_offset_seconds = -0.5\n",
    "# Extract sampling frequency, check that they are same in all datasets\n",
    "sfreq = dataset.datasets[0].raw.info['sfreq']\n",
    "assert all([ds.raw.info['sfreq'] == sfreq for ds in dataset.datasets])\n",
    "# Calculate the trial start offset in samples.\n",
    "trial_start_offset_samples = int(trial_start_offset_seconds * sfreq)\n",
    "\n",
    "# Create windows using braindecode function for this. It needs parameters to define how\n",
    "# trials should be used.\n",
    "windows_dataset = create_windows_from_events(\n",
    "    dataset,\n",
    "    trial_start_offset_samples=trial_start_offset_samples,\n",
    "    trial_stop_offset_samples=0,\n",
    "    preload=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into training and validation sets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily split the dataset using additional info stored in the\n",
    "description attribute, in this case ``session`` column. We select\n",
    "``T`` for training and ``test`` for validation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "splitted = windows_dataset.split('session')\n",
    "train_set = splitted['session_T']  # Session train\n",
    "valid_set = splitted['session_E']  # Session evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<braindecode.datasets.base.BaseConcatDataset at 0x7f9b2b7e9b10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the deep learning model! Braindecode comes with some\n",
    "predefined convolutional neural network architectures for raw\n",
    "time-domain EEG. Here, we use the shallow ConvNet model from [3]_. These models are\n",
    "pure [PyTorch](https://pytorch.org)_ deep learning models, therefore\n",
    "to use your own model, it just has to be a normal PyTorch\n",
    "[nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)_.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShallowFBCSPNet(\n",
      "  (ensuredims): Ensure4d()\n",
      "  (dimshuffle): Expression(expression=transpose_time_to_spat) \n",
      "  (conv_time): Conv2d(1, 40, kernel_size=(25, 1), stride=(1, 1))\n",
      "  (conv_spat): Conv2d(40, 40, kernel_size=(1, 22), stride=(1, 1), bias=False)\n",
      "  (bnorm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_nonlin_exp): Expression(expression=square) \n",
      "  (pool): AvgPool2d(kernel_size=(75, 1), stride=(15, 1), padding=0)\n",
      "  (pool_nonlin_exp): Expression(expression=safe_log) \n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (conv_classifier): Conv2d(40, 4, kernel_size=(69, 1), stride=(1, 1))\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      "  (squeeze): Expression(expression=squeeze_final_output) \n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/braindecode/util.py:51: UserWarning: torch.backends.cudnn.benchmark was set to True which may results in lack of reproducibility. In some cases to ensure reproducibility you may need to set torch.backends.cudnn.benchmark to False.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from braindecode.models import ShallowFBCSPNet\n",
    "from braindecode.util import set_random_seeds\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "# Set random seed to be able to roughly reproduce results\n",
    "# Note that with cudnn benchmark set to True, GPU indeterminism\n",
    "# may still make results substantially different between runs.\n",
    "# To obtain more consistent results at the cost of increased computation time,\n",
    "# you can set `cudnn_benchmark=False` in `set_random_seeds`\n",
    "# or remove `torch.backends.cudnn.benchmark = True`\n",
    "seed = 20200220\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "n_classes = 4\n",
    "classes = list(range(n_classes))\n",
    "# Extract number of chans and time steps from dataset\n",
    "n_chans = train_set[0][0].shape[0]\n",
    "input_window_samples = train_set[0][0].shape[1]\n",
    "\n",
    "model = ShallowFBCSPNet(\n",
    "    n_chans,\n",
    "    n_classes,\n",
    "    input_window_samples=input_window_samples,\n",
    "    final_conv_length='auto',\n",
    ")\n",
    "\n",
    "# Display torchinfo table describing the model\n",
    "print(model)\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train the network! ``EEGClassifier`` is a Braindecode object\n",
    "responsible for managing the training of neural networks. It inherits\n",
    "from skorch [NeuralNetClassifier](https://skorch.readthedocs.io/en/stable/classifier.html#)_,\n",
    "so the training logic is the same as in [Skorch](https://skorch.readthedocs.io/en/stable/)_.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>In this tutorial, we use some default parameters that we\n",
    "   have found to work well for motor decoding, however we strongly\n",
    "   encourage you to perform your own hyperparameter optimization using\n",
    "   cross validation on your training data.</p></div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr      dur\n",
      "-------  ----------------  ------------  ----------------  ------------  ------  -------\n",
      "      1            \u001b[36m0.2500\u001b[0m        \u001b[32m1.5987\u001b[0m            \u001b[35m0.2500\u001b[0m        \u001b[31m3.8199\u001b[0m  0.0006  11.2333\n",
      "      2            \u001b[36m0.2535\u001b[0m        \u001b[32m1.3392\u001b[0m            \u001b[35m0.2535\u001b[0m        \u001b[31m2.4532\u001b[0m  0.0005  0.4518\n",
      "      3            \u001b[36m0.2674\u001b[0m        \u001b[32m1.2163\u001b[0m            \u001b[35m0.2778\u001b[0m        \u001b[31m2.1120\u001b[0m  0.0002  0.4611\n",
      "      4            \u001b[36m0.2778\u001b[0m        \u001b[32m1.1318\u001b[0m            \u001b[35m0.2847\u001b[0m        \u001b[31m1.8968\u001b[0m  0.0000  0.4530\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "# We found these values to be good for the shallow network:\n",
    "lr = 0.0625 * 0.01\n",
    "weight_decay = 0\n",
    "\n",
    "# For deep4 they should be:\n",
    "# lr = 1 * 0.01\n",
    "# weight_decay = 0.5 * 0.001\n",
    "\n",
    "batch_size = 64\n",
    "n_epochs = 4\n",
    "\n",
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.NLLLoss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    train_split=predefined_split(valid_set),  # using valid_set for validation\n",
    "    optimizer__lr=lr,\n",
    "    optimizer__weight_decay=weight_decay,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,\n",
    "    classes=classes,\n",
    ")\n",
    "# Model training for the specified number of epochs. `y` is None as it is\n",
    "# already supplied in the dataset.\n",
    "_ = clf.fit(train_set, y=None, epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the history stored by Skorch throughout training to plot\n",
    "accuracy and loss curves.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Extract loss and accuracy values for plotting from history object\n",
    "results_columns = ['train_loss', 'valid_loss', 'train_accuracy', 'valid_accuracy']\n",
    "df = pd.DataFrame(clf.history[:, results_columns], columns=results_columns,\n",
    "                  index=clf.history[:, 'epoch'])\n",
    "\n",
    "# get percent of misclass for better visual comparison to loss\n",
    "df = df.assign(train_misclass=100 - 100 * df.train_accuracy,\n",
    "               valid_misclass=100 - 100 * df.valid_accuracy)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(8, 3))\n",
    "df.loc[:, ['train_loss', 'valid_loss']].plot(\n",
    "    ax=ax1, style=['-', ':'], marker='o', color='tab:blue', legend=False, fontsize=14)\n",
    "\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue', labelsize=14)\n",
    "ax1.set_ylabel(\"Loss\", color='tab:blue', fontsize=14)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "df.loc[:, ['train_misclass', 'valid_misclass']].plot(\n",
    "    ax=ax2, style=['-', ':'], marker='o', color='tab:red', legend=False)\n",
    "ax2.tick_params(axis='y', labelcolor='tab:red', labelsize=14)\n",
    "ax2.set_ylabel(\"Misclassification Rate [%]\", color='tab:red', fontsize=14)\n",
    "ax2.set_ylim(ax2.get_ylim()[0], 85)  # make some room for legend\n",
    "ax1.set_xlabel(\"Epoch\", fontsize=14)\n",
    "\n",
    "# where some data has already been plotted to ax\n",
    "handles = []\n",
    "handles.append(Line2D([0], [0], color='black', linewidth=1, linestyle='-', label='Train'))\n",
    "handles.append(Line2D([0], [0], color='black', linewidth=1, linestyle=':', label='Valid'))\n",
    "plt.legend(handles, [h.get_label() for h in handles], fontsize=14)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting a  Confusion Matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we generate a confusion matrix as in [3]_.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from braindecode.visualization import plot_confusion_matrix\n",
    "\n",
    "# generate confusion matrices\n",
    "# get the targets\n",
    "y_true = valid_set.get_metadata().target\n",
    "y_pred = clf.predict(valid_set)\n",
    "\n",
    "# generating confusion matrix\n",
    "confusion_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# add class labels\n",
    "# label_dict is class_name : str -> i_class : int\n",
    "label_dict = windows_dataset.datasets[0].window_kwargs[0][1]['mapping']\n",
    "# sort the labels by values (values are integer class labels)\n",
    "labels = [k for k, v in sorted(label_dict.items(), key=lambda kv: kv[1])]\n",
    "\n",
    "# plot the basic conf. matrix\n",
    "plot_confusion_matrix(confusion_mat, class_names=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    ".. [1] Tangermann, M., Müller, K.R., Aertsen, A., Birbaumer, N., Braun, C.,\n",
    "       Brunner, C., Leeb, R., Mehring, C., Miller, K.J., Mueller-Putz, G.\n",
    "       and Nolte, G., 2012. Review of the BCI competition IV.\n",
    "       Frontiers in neuroscience, 6, p.55.\n",
    "\n",
    ".. [2] Jayaram, Vinay, and Alexandre Barachant.\n",
    "       \"MOABB: trustworthy algorithm benchmarking for BCIs.\"\n",
    "       Journal of neural engineering 15.6 (2018): 066011.\n",
    "\n",
    ".. [3] Schirrmeister, R.T., Springenberg, J.T., Fiederer, L.D.J., Glasstetter, M.,\n",
    "       Eggensperger, K., Tangermann, M., Hutter, F., Burgard, W. and Ball, T. (2017),\n",
    "       Deep learning with convolutional neural networks for EEG decoding and visualization.\n",
    "       Hum. Brain Mapping, 38: 5391-5420. https://doi.org/10.1002/hbm.23730.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
