{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7DENys3jZNGQ",
        "kux7rdXClzfr",
        "DyvPTrY5ZHSD"
      ],
      "gpuType": "T4",
      "mount_file_id": "1HF5JajkTaQDzJ4wIjBcedyftRxE5gPMb",
      "authorship_tag": "ABX9TyN7XbsZuXww28pELXllf7jS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jbarbon/dgm-2023.2/blob/main/VAE_dados_reais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VAE para representação latente dos dados reais\n",
        "\n",
        "link fonte: https://github.com/arkanivasarkar/EEG-Data-Augmentation-using-Variational-Autoencoder\n",
        "\n",
        "Paper: https://arxiv.org/pdf/1611.08024.pdf"
      ],
      "metadata": {
        "id": "vNS3T0yXTsQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading libraries"
      ],
      "metadata": {
        "id": "7DENys3jZNGQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6exzs4gOtSH",
        "outputId": "69073110-b0c8-4ab4-afeb-a0a6155952de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting np_utils\n",
            "  Downloading np_utils-0.6.0.tar.gz (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from np_utils) (1.23.5)\n",
            "Building wheels for collected packages: np_utils\n",
            "  Building wheel for np_utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for np_utils: filename=np_utils-0.6.0-py3-none-any.whl size=56439 sha256=d8d9da2584184d853345cbb6456386058edfe78a12b6a801efcbec648258812a\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/c7/50/2307607f44366dd021209f660045f8d51cb976514d30be7cc7\n",
            "Successfully built np_utils\n",
            "Installing collected packages: np_utils\n",
            "Successfully installed np_utils-0.6.0\n"
          ]
        }
      ],
      "source": [
        "pip install np_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dp4sLEV0OMux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc137ae9-7496-432e-d3ff-71de5b306765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting braindecode==0.7\n",
            "  Downloading Braindecode-0.7-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.4/184.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mne (from braindecode==0.7)\n",
            "  Downloading mne-1.6.0-py3-none-any.whl (8.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from braindecode==0.7) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from braindecode==0.7) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from braindecode==0.7) (1.11.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from braindecode==0.7) (3.7.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from braindecode==0.7) (3.9.0)\n",
            "Collecting skorch (from braindecode==0.7)\n",
            "  Downloading skorch-0.15.0-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.3/239.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode==0.7) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode==0.7) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode==0.7) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode==0.7) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode==0.7) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode==0.7) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode==0.7) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode==0.7) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne->braindecode==0.7) (4.66.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne->braindecode==0.7) (1.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne->braindecode==0.7) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne->braindecode==0.7) (3.1.2)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne->braindecode==0.7) (0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from mne->braindecode==0.7) (0.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->braindecode==0.7) (2023.3.post1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from skorch->braindecode==0.7) (1.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch->braindecode==0.7) (0.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne->braindecode==0.7) (4.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne->braindecode==0.7) (2.31.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->braindecode==0.7) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch->braindecode==0.7) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch->braindecode==0.7) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne->braindecode==0.7) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode==0.7) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode==0.7) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode==0.7) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode==0.7) (2023.7.22)\n",
            "Installing collected packages: skorch, mne, braindecode\n",
            "Successfully installed braindecode-0.7 mne-1.6.0 skorch-0.15.0\n",
            "Collecting moabb\n",
            "  Downloading moabb-1.0.0-py3-none-any.whl (563 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.8/563.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from moabb) (6.0.1)\n",
            "Collecting coverage<8.0.0,>=7.0.1 (from moabb)\n",
            "  Downloading coverage-7.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.5/227.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting edflib-python<2.0.0,>=1.0.6 (from moabb)\n",
            "  Downloading EDFlib_Python-1.0.8-py3-none-any.whl (26 kB)\n",
            "Collecting h5py<=3.8.0 (from moabb)\n",
            "  Downloading h5py-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib<4.0.0,>=3.6.2 in /usr/local/lib/python3.10/dist-packages (from moabb) (3.7.1)\n",
            "Collecting memory-profiler<0.62.0,>=0.61.0 (from moabb)\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: mne<2.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from moabb) (1.6.0)\n",
            "Collecting mne-bids<0.14,>=0.13 (from moabb)\n",
            "  Downloading mne_bids-0.13-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.22 in /usr/local/lib/python3.10/dist-packages (from moabb) (1.23.5)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.5.2 in /usr/local/lib/python3.10/dist-packages (from moabb) (1.5.3)\n",
            "Requirement already satisfied: pooch<2.0.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from moabb) (1.8.0)\n",
            "Collecting pyriemann<0.6,>=0.5 (from moabb)\n",
            "  Downloading pyriemann-0.5.tar.gz (119 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.2/119.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytest<8.0.0,>=7.4.0 in /usr/local/lib/python3.10/dist-packages (from moabb) (7.4.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.10/dist-packages (from moabb) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from moabb) (1.2.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.9.3 in /usr/local/lib/python3.10/dist-packages (from moabb) (1.11.3)\n",
            "Requirement already satisfied: seaborn<0.13.0,>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from moabb) (0.12.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from moabb) (4.66.1)\n",
            "Collecting urllib3<2.0.0,>=1.26.15 (from moabb)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (2.8.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory-profiler<0.62.0,>=0.61.0->moabb) (5.9.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne<2.0,>=1.4->moabb) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne<2.0,>=1.4->moabb) (3.1.2)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne<2.0,>=1.4->moabb) (0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from mne<2.0,>=1.4->moabb) (0.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.5.2->moabb) (2023.3.post1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch<2.0.0,>=1.6.0->moabb) (4.0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pyriemann<0.6,>=0.5->moabb) (1.3.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest<8.0.0,>=7.4.0->moabb) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest<8.0.0,>=7.4.0->moabb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest<8.0.0,>=7.4.0->moabb) (1.1.3)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest<8.0.0,>=7.4.0->moabb) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.28.1->moabb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.28.1->moabb) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.28.1->moabb) (2023.7.22)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.2.0->moabb) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.6.2->moabb) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne<2.0,>=1.4->moabb) (2.1.3)\n",
            "Building wheels for collected packages: pyriemann\n",
            "  Building wheel for pyriemann (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyriemann: filename=pyriemann-0.5-py2.py3-none-any.whl size=107752 sha256=da58700dee9236a048fb2584f652b548e1916d6f2cc00331235ab923eea59284\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/86/79/622e9c1dc933dc088e287ebfaac5aa9bdc6a38a9db193ce1f1\n",
            "Successfully built pyriemann\n",
            "Installing collected packages: urllib3, memory-profiler, h5py, edflib-python, coverage, pyriemann, mne-bids, moabb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "Successfully installed coverage-7.3.2 edflib-python-1.0.8 h5py-3.8.0 memory-profiler-0.61.0 mne-bids-0.13 moabb-1.0.0 pyriemann-0.5 urllib3-1.26.18\n"
          ]
        }
      ],
      "source": [
        "!pip install braindecode==0.7\n",
        "!pip install moabb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn\n",
        "import umap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cunUQKU6qt0",
        "outputId": "9c7f1f92-740b-4469-accc-bf290303fbc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting umap-learn\n",
            "  Downloading umap-learn-0.5.5.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.2.2)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.58.1)\n",
            "Collecting pynndescent>=0.5 (from umap-learn)\n",
            "  Downloading pynndescent-0.5.11-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.66.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn) (0.41.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.2.0)\n",
            "Building wheels for collected packages: umap-learn\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.5-py3-none-any.whl size=86831 sha256=d2c99491c83cbef0cd07cc3e8d911aef989d7dd07d9fcf03a0ca44db713cda5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/70/07/428d2b58660a1a3b431db59b806a10da736612ebbc66c1bcc5\n",
            "Successfully built umap-learn\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.11 umap-learn-0.5.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2_9NgpdOPHY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a0e9489-74ec-4aba-d837-bcda7eafa013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "/usr/local/lib/python3.10/dist-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision import transforms, utils\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(0) # Set for our testing purposes, please do not change!\n",
        "\n",
        "from braindecode.datasets import MOABBDataset\n",
        "from braindecode.preprocessing import (\n",
        "    exponential_moving_standardize, preprocess, Preprocessor)\n",
        "from braindecode.preprocessing import \\\n",
        "    create_windows_from_events, create_fixed_length_windows\n",
        "from sklearn.preprocessing import scale as standard_scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2N7BshTkTrdK"
      },
      "outputs": [],
      "source": [
        "#bibliotecas para carregar o dataset e para arquitetura da rede\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, BatchNormalization, LeakyReLU, Dense, Lambda, Reshape, Flatten, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import mse\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bibliotecas para visualização do espaço latente\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "vu5Yc7k8hEj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kux7rdXClzfr"
      },
      "source": [
        "## Reading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMuPSk7KORh5"
      },
      "outputs": [],
      "source": [
        "def preprocessor(\n",
        "    dataset,\n",
        "    low_cut_hz = 4.,   # low cut frequency for filtering\n",
        "    high_cut_hz = 38., # high cut frequency for filtering\n",
        "    newfreq = 100, # Paramater for resampling\n",
        "    factor = 1e6, # Parameter for scaling\n",
        "    ):\n",
        "\n",
        "    preprocessors = [\n",
        "        Preprocessor('pick_types', eeg=True, meg=False, stim=False),  # Keep EEG sensors\n",
        "#         Preprocessor(lambda data: np.multiply(data, factor)),  # Convert from V to uV\n",
        "        Preprocessor(\"resample\", sfreq=newfreq), # Resampling\n",
        "        Preprocessor('filter', l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter\n",
        "        Preprocessor(\"set_eeg_reference\", ref_channels=\"average\", ch_type=\"eeg\"), # Common Average Reference\n",
        "        Preprocessor(standard_scale, channel_wise=True) ## Standard Scale window\n",
        "    ]\n",
        "\n",
        "    # Transform the data\n",
        "    # return preprocess(dataset, preprocessors, n_jobs = -1)\n",
        "    return preprocess(dataset, preprocessors)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTJ5ZyPDOSay"
      },
      "outputs": [],
      "source": [
        "def get_windows(\n",
        "        dataset,\n",
        "        trial_start_offset_samples=0,\n",
        "        trial_stop_offset_samples=100,\n",
        "        window_size_samples=400,\n",
        "        window_stride_samples=100,\n",
        "        preload=True,\n",
        "        # mapping = {'left_hand': 0, 'right_hand': 1},\n",
        "        picks = ['C3', 'Cz', 'C4']\n",
        "        ):\n",
        "\n",
        "    windows_dataset = create_windows_from_events(\n",
        "        dataset,\n",
        "        trial_start_offset_samples = trial_start_offset_samples,\n",
        "        trial_stop_offset_samples  = trial_stop_offset_samples,\n",
        "        window_size_samples        = window_size_samples,\n",
        "        window_stride_samples      = window_stride_samples,\n",
        "        preload                    = True,\n",
        "        # mapping = {'left_hand': 0, 'right_hand': 1},\n",
        "        #picks                      = picks\n",
        "        )\n",
        "\n",
        "    # preprocess(windows_dataset, [Preprocessor(standard_scale, channel_wise=True)]) ## Standard Scale window\n",
        "\n",
        "    return windows_dataset\n",
        "\n",
        "\n",
        "def get_tensors_from_windows(windows_dataset):\n",
        "    windows_list = []\n",
        "    labels_list = []\n",
        "    n_runs = len(windows_dataset.datasets)\n",
        "    for i in range(n_runs):\n",
        "        windows_list.append(windows_dataset.datasets[i].windows.get_data())\n",
        "        labels_list.append(windows_dataset.datasets[i].y)\n",
        "\n",
        "    stacked_tensor = np.concatenate(windows_list, axis=0)\n",
        "    stacked_labels = np.concatenate(labels_list, axis=0)\n",
        "\n",
        "    del windows_list,labels_list\n",
        "\n",
        "    return stacked_tensor, stacked_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Khk7czwQOUKI"
      },
      "outputs": [],
      "source": [
        "class EEG(Dataset):\n",
        "\n",
        "    def __init__(self, subject_id = 3, dataset_name=\"BNCI2014_001\", transform = None):\n",
        "\n",
        "        self.raw_dataset     = MOABBDataset(dataset_name = dataset_name, subject_ids=subject_id)\n",
        "        self.prepro_dataset  = preprocessor(self.raw_dataset)\n",
        "        self.windows_dataset = get_windows(self.prepro_dataset)\n",
        "        self.data            = get_tensors_from_windows(self.windows_dataset)\n",
        "        self.transform       = transform\n",
        "        self.classes         = self.windows_dataset.datasets[0].windows.event_id\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data[0].shape[0]\n",
        "\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "\n",
        "        # sample = {'signal': torch.from_numpy(self.data[0])[idx], 'label': torch.from_numpy(self.data[1])[idx]}\n",
        "\n",
        "        sample = (torch.from_numpy(np.expand_dims(self.data[0], axis = 1))[idx], torch.from_numpy(self.data[1])[idx])\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSlLVHEpOWRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44532801-5b2d-438e-d362-a7d26a01079e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/moabb/datasets/download.py:55: RuntimeWarning: Setting non-standard config type: \"MNE_DATASETS_BNCI_PATH\"\n",
            "  set_config(key, get_config(\"MNE_DATA\"))\n",
            "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A03T.mat' to file '/root/mne_data/MNE-bnci-data/database/data-sets/001-2014/A03T.mat'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNE_DATA is not already configured. It will be set to default location in the home directory - /root/mne_data\n",
            "All datasets will be downloaded to this location, if anything is already downloaded, please move manually to this location\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'lampx.tugraz.at'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
            "  warnings.warn(\n",
            "100%|█████████████████████████████████████| 44.1M/44.1M [00:00<00:00, 23.2GB/s]\n",
            "SHA256 hash of downloaded file: 7e731ee8b681d5da6ecb11ae1d4e64b1653c7f15aad5d6b7620b25ce53141e80\n",
            "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
            "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A03E.mat' to file '/root/mne_data/MNE-bnci-data/database/data-sets/001-2014/A03E.mat'.\n",
            "100%|█████████████████████████████████████| 42.3M/42.3M [00:00<00:00, 16.2GB/s]\n",
            "SHA256 hash of downloaded file: d4229267ec7624fa8bd3af5cbebac17f415f7c722de6cb676748f8cb3b717d97\n",
            "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-6d7742e8d404>:33: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  windows_list.append(windows_dataset.datasets[i].windows.get_data())\n",
            "<ipython-input-8-6d7742e8d404>:33: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  windows_list.append(windows_dataset.datasets[i].windows.get_data())\n",
            "<ipython-input-8-6d7742e8d404>:33: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  windows_list.append(windows_dataset.datasets[i].windows.get_data())\n",
            "<ipython-input-8-6d7742e8d404>:33: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  windows_list.append(windows_dataset.datasets[i].windows.get_data())\n",
            "<ipython-input-8-6d7742e8d404>:33: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  windows_list.append(windows_dataset.datasets[i].windows.get_data())\n",
            "<ipython-input-8-6d7742e8d404>:33: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  windows_list.append(windows_dataset.datasets[i].windows.get_data())\n",
            "<ipython-input-8-6d7742e8d404>:33: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  windows_list.append(windows_dataset.datasets[i].windows.get_data())\n",
            "<ipython-input-8-6d7742e8d404>:33: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  windows_list.append(windows_dataset.datasets[i].windows.get_data())\n",
            "<ipython-input-8-6d7742e8d404>:33: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  windows_list.append(windows_dataset.datasets[i].windows.get_data())\n",
            "<ipython-input-8-6d7742e8d404>:33: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  windows_list.append(windows_dataset.datasets[i].windows.get_data())\n",
            "<ipython-input-8-6d7742e8d404>:33: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  windows_list.append(windows_dataset.datasets[i].windows.get_data())\n",
            "<ipython-input-8-6d7742e8d404>:33: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  windows_list.append(windows_dataset.datasets[i].windows.get_data())\n"
          ]
        }
      ],
      "source": [
        "my_eeg_data = EEG(subject_id=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqFlNRrgOZgZ"
      },
      "outputs": [],
      "source": [
        "x = my_eeg_data[:][0].detach().numpy()\n",
        "eletrodos = x.shape[2]\n",
        "amostras  = x.shape[3]\n",
        "y = my_eeg_data[:][1].detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvMYCDnWlzfr"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle = True, stratify = y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_val = tf.reduce_min(X_train)\n",
        "max_val = tf.reduce_max(X_train)\n",
        "\n",
        "X_train = (X_train - min_val) / (max_val - min_val) #Normalizando os dados\n",
        "X_test = (X_test - min_val) / (max_val - min_val)\n",
        "\n",
        "X_train = tf.cast(X_train, tf.float32) #Lança um tensor para um novo tipo.\n",
        "X_test = tf.cast(X_test, tf.float32)"
      ],
      "metadata": {
        "id": "2yg0X8gA2OS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##VAE"
      ],
      "metadata": {
        "id": "DyvPTrY5ZHSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE model\n",
        "input_shape=(X_train.shape[1:])\n",
        "batch_size = 32\n",
        "kernel_size = 5\n",
        "filters = 16\n",
        "latent_dim = 2\n",
        "epochs = 1000\n",
        "\n",
        "# reparameterization\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# encoder\n",
        "inputs = Input(shape=input_shape, name='encoder_input')\n",
        "x = inputs\n",
        "\n",
        "filters = filters* 2\n",
        "x = Conv2D(filters=filters,kernel_size=(1, 50),strides=(1,25),padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "\n",
        "filters = filters* 2\n",
        "x = Conv2D(filters=filters,kernel_size=(eletrodos, 1),padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "shape = K.int_shape(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(16, activation='relu')(x)\n",
        "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
        "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
        "z_log_var = z_log_var + 1e-8\n",
        "\n",
        "# reparameterization\n",
        "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
        "\n",
        "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "encoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfyuCzumYZSy",
        "outputId": "c38042fe-a2b4-40b0-98a0-6ff173e88184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)  [(None, 1, 22, 400)]         0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 1, 1, 32)             640032    ['encoder_input[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 1, 1, 32)             128       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)     (None, 1, 1, 32)             0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 1, 1, 64)             45120     ['leaky_re_lu[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 1, 1, 64)             256       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 1, 1, 64)             0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 64)                   0         ['leaky_re_lu_1[0][0]']       \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 16)                   1040      ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " z_log_var (Dense)           (None, 2)                    34        ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " z_mean (Dense)              (None, 2)                    34        ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " tf.math.add (TFOpLambda)    (None, 2)                    0         ['z_log_var[0][0]']           \n",
            "                                                                                                  \n",
            " z (Lambda)                  (None, 2)                    0         ['z_mean[0][0]',              \n",
            "                                                                     'tf.math.add[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 686644 (2.62 MB)\n",
            "Trainable params: 686452 (2.62 MB)\n",
            "Non-trainable params: 192 (768.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder\n",
        "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
        "x = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\n",
        "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
        "\n",
        "x = Conv2DTranspose(filters=filters,kernel_size=(eletrodos, 1),activation='relu',)(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "filters = filters// 2\n",
        "x = Conv2DTranspose(filters=filters,kernel_size=(1, 400),activation='relu',strides=(1,25))(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "filters = filters// 2\n",
        "outputs = Conv2DTranspose(filters=1,kernel_size=kernel_size,padding='same',name='decoder_output')(x)\n",
        "outputs = Reshape((1,eletrodos,400))(outputs)\n",
        "\n",
        "decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "decoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIxwpjEuYakR",
        "outputId": "34437557-036f-49bd-ffc1-39d382089bf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " z_sampling (InputLayer)     [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                192       \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 1, 1, 64)          0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTr  (None, 22, 1, 64)         90176     \n",
            " anspose)                                                        \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 22, 1, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2D  (None, 22, 400, 32)       819232    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 22, 400, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " decoder_output (Conv2DTran  (None, 22, 400, 1)        801       \n",
            " spose)                                                          \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 1, 22, 400)        0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 910785 (3.47 MB)\n",
            "Trainable params: 910593 (3.47 MB)\n",
            "Non-trainable params: 192 (768.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE model (merging encoder and decoder)\n",
        "outputs = decoder(encoder(inputs)[2])\n",
        "vae = Model(inputs, outputs, name='vae')\n",
        "vae.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWQ90acMYeWI",
        "outputId": "c9afeb1a-7e30-4c42-8c25-3c2d1c3bb9d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vae\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_input (InputLayer)  [(None, 1, 22, 400)]      0         \n",
            "                                                                 \n",
            " encoder (Functional)        [(None, 2),               686644    \n",
            "                              (None, 2),                         \n",
            "                              (None, 2)]                         \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 1, 22, 400)        910785    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1597429 (6.09 MB)\n",
            "Trainable params: 1597045 (6.09 MB)\n",
            "Non-trainable params: 384 (1.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer\n",
        "optimizer = Adam(learning_rate=0.001, beta_1=0.5, beta_2=0.999)\n",
        "\n",
        "# compiling vae\n",
        "vae.compile(optimizer=optimizer, loss= 'mse', metrics = 'accuracy')\n",
        "vae.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LkcEw7IYg1Q",
        "outputId": "5d42de83-f073-45cd-ae4a-ea061822c1f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vae\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_input (InputLayer)  [(None, 1, 22, 400)]      0         \n",
            "                                                                 \n",
            " encoder (Functional)        [(None, 2),               686644    \n",
            "                              (None, 2),                         \n",
            "                              (None, 2)]                         \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 1, 22, 400)        910785    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1597429 (6.09 MB)\n",
            "Trainable params: 1597045 (6.09 MB)\n",
            "Non-trainable params: 384 (1.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit vae model\n",
        "history = vae.fit(X_train,X_train,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(X_test, X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skf1GHMwYkwj",
        "outputId": "1d3659ee-64b9-4587-e307-d62e2ef64f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "29/29 [==============================] - 17s 78ms/step - loss: 0.1042 - accuracy: 0.0029 - val_loss: 0.1587 - val_accuracy: 0.0028\n",
            "Epoch 2/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0119 - accuracy: 0.0032 - val_loss: 0.1540 - val_accuracy: 0.0024\n",
            "Epoch 3/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0080 - accuracy: 0.0021 - val_loss: 0.1474 - val_accuracy: 0.0012\n",
            "Epoch 4/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0062 - accuracy: 0.0024 - val_loss: 0.1413 - val_accuracy: 0.0022\n",
            "Epoch 5/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0058 - accuracy: 0.0026 - val_loss: 0.1350 - val_accuracy: 0.0018\n",
            "Epoch 6/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0065 - accuracy: 0.0026 - val_loss: 0.1250 - val_accuracy: 0.0020\n",
            "Epoch 7/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0046 - accuracy: 0.0039 - val_loss: 0.1203 - val_accuracy: 0.0018\n",
            "Epoch 8/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0044 - accuracy: 0.0036 - val_loss: 0.1152 - val_accuracy: 0.0026\n",
            "Epoch 9/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0047 - accuracy: 0.0037 - val_loss: 0.1049 - val_accuracy: 0.0022\n",
            "Epoch 10/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0043 - accuracy: 0.0041 - val_loss: 0.0983 - val_accuracy: 0.0012\n",
            "Epoch 11/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0050 - accuracy: 0.0035 - val_loss: 0.0886 - val_accuracy: 0.0016\n",
            "Epoch 12/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0040 - accuracy: 0.0041 - val_loss: 0.0835 - val_accuracy: 0.0020\n",
            "Epoch 13/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.0041 - val_loss: 0.0727 - val_accuracy: 0.0028\n",
            "Epoch 14/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.0044 - val_loss: 0.0614 - val_accuracy: 0.0022\n",
            "Epoch 15/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.0049 - val_loss: 0.0550 - val_accuracy: 0.0016\n",
            "Epoch 16/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0036 - accuracy: 0.0051 - val_loss: 0.0453 - val_accuracy: 0.0030\n",
            "Epoch 17/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0036 - accuracy: 0.0049 - val_loss: 0.0401 - val_accuracy: 0.0030\n",
            "Epoch 18/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0038 - accuracy: 0.0038 - val_loss: 0.0305 - val_accuracy: 0.0035\n",
            "Epoch 19/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.0051 - val_loss: 0.0241 - val_accuracy: 0.0018\n",
            "Epoch 20/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0035 - accuracy: 0.0048 - val_loss: 0.0184 - val_accuracy: 0.0024\n",
            "Epoch 21/1000\n",
            "29/29 [==============================] - 1s 40ms/step - loss: 0.0038 - accuracy: 0.0038 - val_loss: 0.0133 - val_accuracy: 0.0031\n",
            "Epoch 22/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.0051 - val_loss: 0.0099 - val_accuracy: 0.0026\n",
            "Epoch 23/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0036 - accuracy: 0.0036 - val_loss: 0.0068 - val_accuracy: 0.0022\n",
            "Epoch 24/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.0044 - val_loss: 0.0071 - val_accuracy: 0.0028\n",
            "Epoch 25/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.0046 - val_loss: 0.0053 - val_accuracy: 0.0033\n",
            "Epoch 26/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.0046 - val_loss: 0.0047 - val_accuracy: 0.0024\n",
            "Epoch 27/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0034 - accuracy: 0.0037 - val_loss: 0.0035 - val_accuracy: 0.0035\n",
            "Epoch 28/1000\n",
            "29/29 [==============================] - 1s 33ms/step - loss: 0.0033 - accuracy: 0.0049 - val_loss: 0.0033 - val_accuracy: 0.0035\n",
            "Epoch 29/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 0.0047 - val_loss: 0.0031 - val_accuracy: 0.0061\n",
            "Epoch 30/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 0.0051 - val_loss: 0.0031 - val_accuracy: 0.0047\n",
            "Epoch 31/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 0.0047 - val_loss: 0.0031 - val_accuracy: 0.0039\n",
            "Epoch 32/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 0.0050 - val_loss: 0.0030 - val_accuracy: 0.0022\n",
            "Epoch 33/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 0.0042 - val_loss: 0.0030 - val_accuracy: 0.0041\n",
            "Epoch 34/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 0.0055 - val_loss: 0.0030 - val_accuracy: 0.0045\n",
            "Epoch 35/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 0.0050 - val_loss: 0.0029 - val_accuracy: 0.0041\n",
            "Epoch 36/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 0.0042 - val_loss: 0.0031 - val_accuracy: 0.0033\n",
            "Epoch 37/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 0.0047 - val_loss: 0.0030 - val_accuracy: 0.0043\n",
            "Epoch 38/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 0.0056 - val_loss: 0.0033 - val_accuracy: 0.0053\n",
            "Epoch 39/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0031 - accuracy: 0.0046 - val_loss: 0.0030 - val_accuracy: 0.0073\n",
            "Epoch 40/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 0.0046 - val_loss: 0.0031 - val_accuracy: 0.0049\n",
            "Epoch 41/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0031 - accuracy: 0.0050 - val_loss: 0.0031 - val_accuracy: 0.0047\n",
            "Epoch 42/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0031 - accuracy: 0.0047 - val_loss: 0.0030 - val_accuracy: 0.0037\n",
            "Epoch 43/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 0.0040 - val_loss: 0.0030 - val_accuracy: 0.0037\n",
            "Epoch 44/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0031 - accuracy: 0.0058 - val_loss: 0.0031 - val_accuracy: 0.0063\n",
            "Epoch 45/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0031 - accuracy: 0.0060 - val_loss: 0.0030 - val_accuracy: 0.0069\n",
            "Epoch 46/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0031 - accuracy: 0.0058 - val_loss: 0.0030 - val_accuracy: 0.0081\n",
            "Epoch 47/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 0.0061 - val_loss: 0.0030 - val_accuracy: 0.0073\n",
            "Epoch 48/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0031 - accuracy: 0.0058 - val_loss: 0.0030 - val_accuracy: 0.0067\n",
            "Epoch 49/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0031 - accuracy: 0.0053 - val_loss: 0.0030 - val_accuracy: 0.0071\n",
            "Epoch 50/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0055 - val_loss: 0.0030 - val_accuracy: 0.0047\n",
            "Epoch 51/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 0.0050 - val_loss: 0.0030 - val_accuracy: 0.0069\n",
            "Epoch 52/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 0.0059 - val_loss: 0.0029 - val_accuracy: 0.0051\n",
            "Epoch 53/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0030 - accuracy: 0.0054 - val_loss: 0.0029 - val_accuracy: 0.0071\n",
            "Epoch 54/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0031 - accuracy: 0.0059 - val_loss: 0.0030 - val_accuracy: 0.0043\n",
            "Epoch 55/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 0.0057 - val_loss: 0.0029 - val_accuracy: 0.0085\n",
            "Epoch 56/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0030 - accuracy: 0.0055 - val_loss: 0.0030 - val_accuracy: 0.0069\n",
            "Epoch 57/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0031 - accuracy: 0.0050 - val_loss: 0.0029 - val_accuracy: 0.0063\n",
            "Epoch 58/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0031 - accuracy: 0.0060 - val_loss: 0.0029 - val_accuracy: 0.0045\n",
            "Epoch 59/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0031 - accuracy: 0.0053 - val_loss: 0.0030 - val_accuracy: 0.0075\n",
            "Epoch 60/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 0.0058 - val_loss: 0.0030 - val_accuracy: 0.0065\n",
            "Epoch 61/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 0.0065 - val_loss: 0.0030 - val_accuracy: 0.0043\n",
            "Epoch 62/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0030 - accuracy: 0.0054 - val_loss: 0.0029 - val_accuracy: 0.0075\n",
            "Epoch 63/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0031 - accuracy: 0.0060 - val_loss: 0.0031 - val_accuracy: 0.0049\n",
            "Epoch 64/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0031 - accuracy: 0.0054 - val_loss: 0.0029 - val_accuracy: 0.0077\n",
            "Epoch 65/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 0.0060 - val_loss: 0.0029 - val_accuracy: 0.0047\n",
            "Epoch 66/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 0.0065 - val_loss: 0.0029 - val_accuracy: 0.0031\n",
            "Epoch 67/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0059 - val_loss: 0.0030 - val_accuracy: 0.0041\n",
            "Epoch 68/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 0.0052 - val_loss: 0.0030 - val_accuracy: 0.0063\n",
            "Epoch 69/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0054 - val_loss: 0.0030 - val_accuracy: 0.0081\n",
            "Epoch 70/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 0.0055 - val_loss: 0.0029 - val_accuracy: 0.0061\n",
            "Epoch 71/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 0.0065 - val_loss: 0.0029 - val_accuracy: 0.0063\n",
            "Epoch 72/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 0.0050 - val_loss: 0.0029 - val_accuracy: 0.0047\n",
            "Epoch 73/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0056 - val_loss: 0.0030 - val_accuracy: 0.0033\n",
            "Epoch 74/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 0.0063 - val_loss: 0.0029 - val_accuracy: 0.0051\n",
            "Epoch 75/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 0.0064 - val_loss: 0.0029 - val_accuracy: 0.0081\n",
            "Epoch 76/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 0.0062 - val_loss: 0.0030 - val_accuracy: 0.0047\n",
            "Epoch 77/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0059 - val_loss: 0.0029 - val_accuracy: 0.0039\n",
            "Epoch 78/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0056 - val_loss: 0.0029 - val_accuracy: 0.0051\n",
            "Epoch 79/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0031 - accuracy: 0.0056 - val_loss: 0.0033 - val_accuracy: 0.0059\n",
            "Epoch 80/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 0.0062 - val_loss: 0.0030 - val_accuracy: 0.0043\n",
            "Epoch 81/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 0.0062 - val_loss: 0.0030 - val_accuracy: 0.0049\n",
            "Epoch 82/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 0.0065 - val_loss: 0.0029 - val_accuracy: 0.0079\n",
            "Epoch 83/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 0.0060 - val_loss: 0.0029 - val_accuracy: 0.0061\n",
            "Epoch 84/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 0.0060 - val_loss: 0.0029 - val_accuracy: 0.0071\n",
            "Epoch 85/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0068 - val_loss: 0.0029 - val_accuracy: 0.0049\n",
            "Epoch 86/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 0.0055 - val_loss: 0.0029 - val_accuracy: 0.0071\n",
            "Epoch 87/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0031 - accuracy: 0.0059 - val_loss: 0.0031 - val_accuracy: 0.0053\n",
            "Epoch 88/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0030 - accuracy: 0.0048 - val_loss: 0.0029 - val_accuracy: 0.0063\n",
            "Epoch 89/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0030 - accuracy: 0.0060 - val_loss: 0.0030 - val_accuracy: 0.0051\n",
            "Epoch 90/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0030 - accuracy: 0.0077 - val_loss: 0.0029 - val_accuracy: 0.0081\n",
            "Epoch 91/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0030 - accuracy: 0.0063 - val_loss: 0.0029 - val_accuracy: 0.0057\n",
            "Epoch 92/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0030 - accuracy: 0.0061 - val_loss: 0.0029 - val_accuracy: 0.0063\n",
            "Epoch 93/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0031 - accuracy: 0.0061 - val_loss: 0.0030 - val_accuracy: 0.0057\n",
            "Epoch 94/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0030 - accuracy: 0.0064 - val_loss: 0.0029 - val_accuracy: 0.0059\n",
            "Epoch 95/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0033 - accuracy: 0.0056 - val_loss: 0.0029 - val_accuracy: 0.0096\n",
            "Epoch 96/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0030 - accuracy: 0.0059 - val_loss: 0.0030 - val_accuracy: 0.0045\n",
            "Epoch 97/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0030 - accuracy: 0.0055 - val_loss: 0.0029 - val_accuracy: 0.0061\n",
            "Epoch 98/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0030 - accuracy: 0.0066 - val_loss: 0.0029 - val_accuracy: 0.0067\n",
            "Epoch 99/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 0.0067 - val_loss: 0.0029 - val_accuracy: 0.0049\n",
            "Epoch 100/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0072 - val_loss: 0.0029 - val_accuracy: 0.0055\n",
            "Epoch 101/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0075 - val_loss: 0.0029 - val_accuracy: 0.0059\n",
            "Epoch 102/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0077 - val_loss: 0.0029 - val_accuracy: 0.0083\n",
            "Epoch 103/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0057 - val_loss: 0.0029 - val_accuracy: 0.0071\n",
            "Epoch 104/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 0.0074 - val_loss: 0.0030 - val_accuracy: 0.0085\n",
            "Epoch 105/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 0.0068 - val_loss: 0.0029 - val_accuracy: 0.0051\n",
            "Epoch 106/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0071 - val_loss: 0.0029 - val_accuracy: 0.0069\n",
            "Epoch 107/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0071 - val_loss: 0.0029 - val_accuracy: 0.0083\n",
            "Epoch 108/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 0.0064 - val_loss: 0.0029 - val_accuracy: 0.0067\n",
            "Epoch 109/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0071 - val_loss: 0.0029 - val_accuracy: 0.0071\n",
            "Epoch 110/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0079 - val_loss: 0.0029 - val_accuracy: 0.0079\n",
            "Epoch 111/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0084 - val_loss: 0.0029 - val_accuracy: 0.0043\n",
            "Epoch 112/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0076 - val_loss: 0.0029 - val_accuracy: 0.0063\n",
            "Epoch 113/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0065 - val_loss: 0.0029 - val_accuracy: 0.0045\n",
            "Epoch 114/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0078 - val_loss: 0.0029 - val_accuracy: 0.0065\n",
            "Epoch 115/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0031 - accuracy: 0.0074 - val_loss: 0.0032 - val_accuracy: 0.0041\n",
            "Epoch 116/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0076 - val_loss: 0.0029 - val_accuracy: 0.0059\n",
            "Epoch 117/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 0.0082 - val_loss: 0.0029 - val_accuracy: 0.0047\n",
            "Epoch 118/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0065 - val_loss: 0.0030 - val_accuracy: 0.0057\n",
            "Epoch 119/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0087 - val_loss: 0.0029 - val_accuracy: 0.0067\n",
            "Epoch 120/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 0.0083 - val_loss: 0.0029 - val_accuracy: 0.0051\n",
            "Epoch 121/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0084 - val_loss: 0.0029 - val_accuracy: 0.0077\n",
            "Epoch 122/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0030 - accuracy: 0.0089 - val_loss: 0.0029 - val_accuracy: 0.0047\n",
            "Epoch 123/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0030 - accuracy: 0.0085 - val_loss: 0.0029 - val_accuracy: 0.0055\n",
            "Epoch 124/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0030 - accuracy: 0.0076 - val_loss: 0.0029 - val_accuracy: 0.0096\n",
            "Epoch 125/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0029 - accuracy: 0.0076 - val_loss: 0.0030 - val_accuracy: 0.0055\n",
            "Epoch 126/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0030 - accuracy: 0.0086 - val_loss: 0.0029 - val_accuracy: 0.0067\n",
            "Epoch 127/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0030 - accuracy: 0.0083 - val_loss: 0.0029 - val_accuracy: 0.0053\n",
            "Epoch 128/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.0086 - val_loss: 0.0029 - val_accuracy: 0.0057\n",
            "Epoch 129/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.0076 - val_loss: 0.0029 - val_accuracy: 0.0055\n",
            "Epoch 130/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0031 - accuracy: 0.0087 - val_loss: 0.0029 - val_accuracy: 0.0057\n",
            "Epoch 131/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 0.0088 - val_loss: 0.0029 - val_accuracy: 0.0059\n",
            "Epoch 132/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.0081 - val_loss: 0.0029 - val_accuracy: 0.0116\n",
            "Epoch 133/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0030 - accuracy: 0.0085 - val_loss: 0.0029 - val_accuracy: 0.0063\n",
            "Epoch 134/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0081 - val_loss: 0.0028 - val_accuracy: 0.0087\n",
            "Epoch 135/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0029 - accuracy: 0.0088 - val_loss: 0.0029 - val_accuracy: 0.0051\n",
            "Epoch 136/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0085 - val_loss: 0.0029 - val_accuracy: 0.0057\n",
            "Epoch 137/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0088 - val_loss: 0.0029 - val_accuracy: 0.0081\n",
            "Epoch 138/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0081 - val_loss: 0.0028 - val_accuracy: 0.0053\n",
            "Epoch 139/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0081 - val_loss: 0.0028 - val_accuracy: 0.0059\n",
            "Epoch 140/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0089 - val_loss: 0.0029 - val_accuracy: 0.0089\n",
            "Epoch 141/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0092 - val_loss: 0.0029 - val_accuracy: 0.0061\n",
            "Epoch 142/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0083 - val_loss: 0.0029 - val_accuracy: 0.0069\n",
            "Epoch 143/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0092 - val_loss: 0.0029 - val_accuracy: 0.0055\n",
            "Epoch 144/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 0.0091 - val_loss: 0.0029 - val_accuracy: 0.0065\n",
            "Epoch 145/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0099 - val_loss: 0.0029 - val_accuracy: 0.0049\n",
            "Epoch 146/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0090 - val_loss: 0.0028 - val_accuracy: 0.0087\n",
            "Epoch 147/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0097 - val_loss: 0.0029 - val_accuracy: 0.0069\n",
            "Epoch 148/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0096 - val_loss: 0.0029 - val_accuracy: 0.0085\n",
            "Epoch 149/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0109 - val_loss: 0.0028 - val_accuracy: 0.0100\n",
            "Epoch 150/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0104 - val_loss: 0.0028 - val_accuracy: 0.0057\n",
            "Epoch 151/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 0.0094 - val_loss: 0.0030 - val_accuracy: 0.0085\n",
            "Epoch 152/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0112 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 153/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0114 - val_loss: 0.0030 - val_accuracy: 0.0083\n",
            "Epoch 154/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0107 - val_loss: 0.0028 - val_accuracy: 0.0102\n",
            "Epoch 155/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.0112 - val_loss: 0.0028 - val_accuracy: 0.0081\n",
            "Epoch 156/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.0103 - val_loss: 0.0028 - val_accuracy: 0.0077\n",
            "Epoch 157/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0029 - accuracy: 0.0103 - val_loss: 0.0029 - val_accuracy: 0.0069\n",
            "Epoch 158/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0030 - accuracy: 0.0120 - val_loss: 0.0028 - val_accuracy: 0.0079\n",
            "Epoch 159/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.0114 - val_loss: 0.0028 - val_accuracy: 0.0087\n",
            "Epoch 160/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.0115 - val_loss: 0.0028 - val_accuracy: 0.0091\n",
            "Epoch 161/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.0107 - val_loss: 0.0029 - val_accuracy: 0.0104\n",
            "Epoch 162/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.0118 - val_loss: 0.0028 - val_accuracy: 0.0087\n",
            "Epoch 163/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0029 - accuracy: 0.0112 - val_loss: 0.0029 - val_accuracy: 0.0069\n",
            "Epoch 164/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0030 - accuracy: 0.0115 - val_loss: 0.0028 - val_accuracy: 0.0116\n",
            "Epoch 165/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.0115 - val_loss: 0.0028 - val_accuracy: 0.0098\n",
            "Epoch 166/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.0115 - val_loss: 0.0028 - val_accuracy: 0.0092\n",
            "Epoch 167/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.0126 - val_loss: 0.0029 - val_accuracy: 0.0077\n",
            "Epoch 168/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.0116 - val_loss: 0.0029 - val_accuracy: 0.0081\n",
            "Epoch 169/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0113 - val_loss: 0.0028 - val_accuracy: 0.0094\n",
            "Epoch 170/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0109 - val_loss: 0.0028 - val_accuracy: 0.0100\n",
            "Epoch 171/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0111 - val_loss: 0.0029 - val_accuracy: 0.0094\n",
            "Epoch 172/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0124 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 173/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0115 - val_loss: 0.0028 - val_accuracy: 0.0094\n",
            "Epoch 174/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0128 - val_loss: 0.0028 - val_accuracy: 0.0096\n",
            "Epoch 175/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0114 - val_loss: 0.0028 - val_accuracy: 0.0104\n",
            "Epoch 176/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0117 - val_loss: 0.0028 - val_accuracy: 0.0096\n",
            "Epoch 177/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0118 - val_loss: 0.0029 - val_accuracy: 0.0100\n",
            "Epoch 178/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0109 - val_loss: 0.0028 - val_accuracy: 0.0108\n",
            "Epoch 179/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0120 - val_loss: 0.0028 - val_accuracy: 0.0089\n",
            "Epoch 180/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0116 - val_loss: 0.0028 - val_accuracy: 0.0100\n",
            "Epoch 181/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0135 - val_loss: 0.0028 - val_accuracy: 0.0083\n",
            "Epoch 182/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0115 - val_loss: 0.0028 - val_accuracy: 0.0087\n",
            "Epoch 183/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0115 - val_loss: 0.0028 - val_accuracy: 0.0098\n",
            "Epoch 184/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0113 - val_loss: 0.0028 - val_accuracy: 0.0114\n",
            "Epoch 185/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0131 - val_loss: 0.0028 - val_accuracy: 0.0087\n",
            "Epoch 186/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0121 - val_loss: 0.0028 - val_accuracy: 0.0087\n",
            "Epoch 187/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0115 - val_loss: 0.0028 - val_accuracy: 0.0069\n",
            "Epoch 188/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0129 - val_loss: 0.0028 - val_accuracy: 0.0091\n",
            "Epoch 189/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0029 - accuracy: 0.0129 - val_loss: 0.0028 - val_accuracy: 0.0077\n",
            "Epoch 190/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.0115 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 191/1000\n",
            "29/29 [==============================] - 1s 32ms/step - loss: 0.0029 - accuracy: 0.0121 - val_loss: 0.0029 - val_accuracy: 0.0100\n",
            "Epoch 192/1000\n",
            "29/29 [==============================] - 1s 36ms/step - loss: 0.0029 - accuracy: 0.0119 - val_loss: 0.0028 - val_accuracy: 0.0083\n",
            "Epoch 193/1000\n",
            "29/29 [==============================] - 1s 41ms/step - loss: 0.0029 - accuracy: 0.0127 - val_loss: 0.0028 - val_accuracy: 0.0094\n",
            "Epoch 194/1000\n",
            "29/29 [==============================] - 1s 51ms/step - loss: 0.0029 - accuracy: 0.0113 - val_loss: 0.0028 - val_accuracy: 0.0100\n",
            "Epoch 195/1000\n",
            "29/29 [==============================] - 1s 39ms/step - loss: 0.0029 - accuracy: 0.0122 - val_loss: 0.0028 - val_accuracy: 0.0096\n",
            "Epoch 196/1000\n",
            "29/29 [==============================] - 1s 33ms/step - loss: 0.0029 - accuracy: 0.0121 - val_loss: 0.0028 - val_accuracy: 0.0098\n",
            "Epoch 197/1000\n",
            "29/29 [==============================] - 1s 35ms/step - loss: 0.0029 - accuracy: 0.0127 - val_loss: 0.0029 - val_accuracy: 0.0079\n",
            "Epoch 198/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0029 - accuracy: 0.0129 - val_loss: 0.0028 - val_accuracy: 0.0094\n",
            "Epoch 199/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0029 - accuracy: 0.0119 - val_loss: 0.0028 - val_accuracy: 0.0092\n",
            "Epoch 200/1000\n",
            "29/29 [==============================] - 1s 30ms/step - loss: 0.0029 - accuracy: 0.0129 - val_loss: 0.0028 - val_accuracy: 0.0110\n",
            "Epoch 201/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.0123 - val_loss: 0.0028 - val_accuracy: 0.0104\n",
            "Epoch 202/1000\n",
            "29/29 [==============================] - 1s 32ms/step - loss: 0.0030 - accuracy: 0.0128 - val_loss: 0.0029 - val_accuracy: 0.0094\n",
            "Epoch 203/1000\n",
            "29/29 [==============================] - 1s 31ms/step - loss: 0.0029 - accuracy: 0.0130 - val_loss: 0.0028 - val_accuracy: 0.0094\n",
            "Epoch 204/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.0135 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 205/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.0115 - val_loss: 0.0028 - val_accuracy: 0.0100\n",
            "Epoch 206/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.0132 - val_loss: 0.0028 - val_accuracy: 0.0114\n",
            "Epoch 207/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.0146 - val_loss: 0.0028 - val_accuracy: 0.0091\n",
            "Epoch 208/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0029 - accuracy: 0.0128 - val_loss: 0.0028 - val_accuracy: 0.0118\n",
            "Epoch 209/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0029 - accuracy: 0.0133 - val_loss: 0.0028 - val_accuracy: 0.0094\n",
            "Epoch 210/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0029 - accuracy: 0.0132 - val_loss: 0.0028 - val_accuracy: 0.0100\n",
            "Epoch 211/1000\n",
            "29/29 [==============================] - 1s 31ms/step - loss: 0.0029 - accuracy: 0.0128 - val_loss: 0.0028 - val_accuracy: 0.0096\n",
            "Epoch 212/1000\n",
            "29/29 [==============================] - 1s 39ms/step - loss: 0.0029 - accuracy: 0.0138 - val_loss: 0.0028 - val_accuracy: 0.0104\n",
            "Epoch 213/1000\n",
            "29/29 [==============================] - 1s 44ms/step - loss: 0.0029 - accuracy: 0.0133 - val_loss: 0.0028 - val_accuracy: 0.0112\n",
            "Epoch 214/1000\n",
            "29/29 [==============================] - 1s 38ms/step - loss: 0.0029 - accuracy: 0.0135 - val_loss: 0.0028 - val_accuracy: 0.0094\n",
            "Epoch 215/1000\n",
            "29/29 [==============================] - 1s 33ms/step - loss: 0.0029 - accuracy: 0.0140 - val_loss: 0.0029 - val_accuracy: 0.0104\n",
            "Epoch 216/1000\n",
            "29/29 [==============================] - 1s 32ms/step - loss: 0.0029 - accuracy: 0.0124 - val_loss: 0.0028 - val_accuracy: 0.0089\n",
            "Epoch 217/1000\n",
            "29/29 [==============================] - 1s 38ms/step - loss: 0.0029 - accuracy: 0.0121 - val_loss: 0.0028 - val_accuracy: 0.0100\n",
            "Epoch 218/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0029 - accuracy: 0.0141 - val_loss: 0.0028 - val_accuracy: 0.0114\n",
            "Epoch 219/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0029 - accuracy: 0.0129 - val_loss: 0.0028 - val_accuracy: 0.0120\n",
            "Epoch 220/1000\n",
            "29/29 [==============================] - 1s 30ms/step - loss: 0.0028 - accuracy: 0.0145 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 221/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.0149 - val_loss: 0.0028 - val_accuracy: 0.0120\n",
            "Epoch 222/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.0156 - val_loss: 0.0028 - val_accuracy: 0.0100\n",
            "Epoch 223/1000\n",
            "29/29 [==============================] - 1s 31ms/step - loss: 0.0028 - accuracy: 0.0154 - val_loss: 0.0028 - val_accuracy: 0.0114\n",
            "Epoch 224/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.0132 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 225/1000\n",
            "29/29 [==============================] - 1s 32ms/step - loss: 0.0029 - accuracy: 0.0153 - val_loss: 0.0028 - val_accuracy: 0.0087\n",
            "Epoch 226/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.0146 - val_loss: 0.0028 - val_accuracy: 0.0098\n",
            "Epoch 227/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0029 - accuracy: 0.0147 - val_loss: 0.0029 - val_accuracy: 0.0104\n",
            "Epoch 228/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0029 - accuracy: 0.0140 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 229/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0138 - val_loss: 0.0028 - val_accuracy: 0.0098\n",
            "Epoch 230/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0029 - accuracy: 0.0165 - val_loss: 0.0028 - val_accuracy: 0.0104\n",
            "Epoch 231/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0029 - accuracy: 0.0150 - val_loss: 0.0028 - val_accuracy: 0.0096\n",
            "Epoch 232/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0029 - accuracy: 0.0149 - val_loss: 0.0028 - val_accuracy: 0.0087\n",
            "Epoch 233/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0029 - accuracy: 0.0147 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 234/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0029 - accuracy: 0.0137 - val_loss: 0.0028 - val_accuracy: 0.0106\n",
            "Epoch 235/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.0149 - val_loss: 0.0028 - val_accuracy: 0.0120\n",
            "Epoch 236/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.0153 - val_loss: 0.0028 - val_accuracy: 0.0106\n",
            "Epoch 237/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0029 - accuracy: 0.0162 - val_loss: 0.0028 - val_accuracy: 0.0100\n",
            "Epoch 238/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0029 - accuracy: 0.0155 - val_loss: 0.0028 - val_accuracy: 0.0098\n",
            "Epoch 239/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0029 - accuracy: 0.0145 - val_loss: 0.0028 - val_accuracy: 0.0110\n",
            "Epoch 240/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0155 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 241/1000\n",
            "29/29 [==============================] - 1s 36ms/step - loss: 0.0029 - accuracy: 0.0145 - val_loss: 0.0028 - val_accuracy: 0.0091\n",
            "Epoch 242/1000\n",
            "29/29 [==============================] - 1s 35ms/step - loss: 0.0028 - accuracy: 0.0153 - val_loss: 0.0028 - val_accuracy: 0.0092\n",
            "Epoch 243/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.0160 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 244/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0029 - accuracy: 0.0179 - val_loss: 0.0028 - val_accuracy: 0.0106\n",
            "Epoch 245/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.0158 - val_loss: 0.0028 - val_accuracy: 0.0114\n",
            "Epoch 246/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.0164 - val_loss: 0.0028 - val_accuracy: 0.0114\n",
            "Epoch 247/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0029 - accuracy: 0.0170 - val_loss: 0.0028 - val_accuracy: 0.0112\n",
            "Epoch 248/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0156 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 249/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0028 - accuracy: 0.0165 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 250/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0029 - accuracy: 0.0162 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 251/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0029 - accuracy: 0.0156 - val_loss: 0.0028 - val_accuracy: 0.0118\n",
            "Epoch 252/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0028 - accuracy: 0.0160 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 253/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0029 - accuracy: 0.0155 - val_loss: 0.0028 - val_accuracy: 0.0112\n",
            "Epoch 254/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0029 - accuracy: 0.0165 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 255/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.0171 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 256/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.0161 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 257/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0029 - accuracy: 0.0172 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 258/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0028 - accuracy: 0.0161 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 259/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.0168 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 260/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0029 - accuracy: 0.0181 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 261/1000\n",
            "29/29 [==============================] - 1s 31ms/step - loss: 0.0029 - accuracy: 0.0171 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 262/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0171 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 263/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0029 - accuracy: 0.0170 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 264/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.0173 - val_loss: 0.0028 - val_accuracy: 0.0118\n",
            "Epoch 265/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0167 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 266/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0029 - accuracy: 0.0172 - val_loss: 0.0028 - val_accuracy: 0.0116\n",
            "Epoch 267/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0029 - accuracy: 0.0174 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 268/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0028 - accuracy: 0.0167 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 269/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.0157 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 270/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.0139 - val_loss: 0.0028 - val_accuracy: 0.0104\n",
            "Epoch 271/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0174 - val_loss: 0.0028 - val_accuracy: 0.0124\n",
            "Epoch 272/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0029 - accuracy: 0.0160 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 273/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0028 - accuracy: 0.0181 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 274/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0029 - accuracy: 0.0172 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 275/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0029 - accuracy: 0.0165 - val_loss: 0.0028 - val_accuracy: 0.0114\n",
            "Epoch 276/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0028 - accuracy: 0.0183 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 277/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0029 - accuracy: 0.0190 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 278/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0163 - val_loss: 0.0028 - val_accuracy: 0.0100\n",
            "Epoch 279/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0028 - accuracy: 0.0185 - val_loss: 0.0028 - val_accuracy: 0.0124\n",
            "Epoch 280/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.0168 - val_loss: 0.0028 - val_accuracy: 0.0116\n",
            "Epoch 281/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0029 - accuracy: 0.0172 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 282/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.0183 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 283/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0029 - accuracy: 0.0180 - val_loss: 0.0028 - val_accuracy: 0.0106\n",
            "Epoch 284/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.0173 - val_loss: 0.0028 - val_accuracy: 0.0120\n",
            "Epoch 285/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.0170 - val_loss: 0.0028 - val_accuracy: 0.0159\n",
            "Epoch 286/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0029 - accuracy: 0.0183 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 287/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.0184 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 288/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0028 - accuracy: 0.0200 - val_loss: 0.0028 - val_accuracy: 0.0116\n",
            "Epoch 289/1000\n",
            "29/29 [==============================] - 1s 30ms/step - loss: 0.0029 - accuracy: 0.0182 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 290/1000\n",
            "29/29 [==============================] - 1s 32ms/step - loss: 0.0028 - accuracy: 0.0174 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 291/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.0175 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 292/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.0179 - val_loss: 0.0028 - val_accuracy: 0.0118\n",
            "Epoch 293/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0029 - accuracy: 0.0182 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 294/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.0183 - val_loss: 0.0028 - val_accuracy: 0.0120\n",
            "Epoch 295/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.0193 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 296/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0029 - accuracy: 0.0185 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 297/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0191 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 298/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0189 - val_loss: 0.0028 - val_accuracy: 0.0112\n",
            "Epoch 299/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.0181 - val_loss: 0.0028 - val_accuracy: 0.0120\n",
            "Epoch 300/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0180 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 301/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0191 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 302/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0029 - accuracy: 0.0194 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 303/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0189 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 304/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0190 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 305/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0188 - val_loss: 0.0028 - val_accuracy: 0.0118\n",
            "Epoch 306/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0192 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 307/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0191 - val_loss: 0.0028 - val_accuracy: 0.0114\n",
            "Epoch 308/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0197 - val_loss: 0.0028 - val_accuracy: 0.0124\n",
            "Epoch 309/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0208 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 310/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0192 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 311/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0194 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 312/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0182 - val_loss: 0.0029 - val_accuracy: 0.0108\n",
            "Epoch 313/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0191 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 314/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0181 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 315/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0185 - val_loss: 0.0028 - val_accuracy: 0.0120\n",
            "Epoch 316/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0199 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 317/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0187 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 318/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0029 - accuracy: 0.0198 - val_loss: 0.0028 - val_accuracy: 0.0098\n",
            "Epoch 319/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0180 - val_loss: 0.0028 - val_accuracy: 0.0108\n",
            "Epoch 320/1000\n",
            "29/29 [==============================] - 1s 30ms/step - loss: 0.0028 - accuracy: 0.0191 - val_loss: 0.0028 - val_accuracy: 0.0104\n",
            "Epoch 321/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.0191 - val_loss: 0.0028 - val_accuracy: 0.0116\n",
            "Epoch 322/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.0190 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 323/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.0201 - val_loss: 0.0028 - val_accuracy: 0.0118\n",
            "Epoch 324/1000\n",
            "29/29 [==============================] - 1s 30ms/step - loss: 0.0028 - accuracy: 0.0212 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 325/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0029 - accuracy: 0.0196 - val_loss: 0.0028 - val_accuracy: 0.0108\n",
            "Epoch 326/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.0203 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 327/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.0198 - val_loss: 0.0028 - val_accuracy: 0.0155\n",
            "Epoch 328/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.0212 - val_loss: 0.0028 - val_accuracy: 0.0161\n",
            "Epoch 329/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0028 - accuracy: 0.0197 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 330/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0028 - accuracy: 0.0184 - val_loss: 0.0028 - val_accuracy: 0.0152\n",
            "Epoch 331/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0209 - val_loss: 0.0028 - val_accuracy: 0.0114\n",
            "Epoch 332/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0220 - val_loss: 0.0028 - val_accuracy: 0.0152\n",
            "Epoch 333/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0195 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 334/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0028 - accuracy: 0.0207 - val_loss: 0.0028 - val_accuracy: 0.0124\n",
            "Epoch 335/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0195 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 336/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0209 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 337/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0028 - accuracy: 0.0189 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 338/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0206 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 339/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0028 - accuracy: 0.0212 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 340/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0227 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 341/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0209 - val_loss: 0.0028 - val_accuracy: 0.0116\n",
            "Epoch 342/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0029 - accuracy: 0.0204 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 343/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0028 - accuracy: 0.0208 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 344/1000\n",
            "29/29 [==============================] - 1s 35ms/step - loss: 0.0028 - accuracy: 0.0199 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 345/1000\n",
            "29/29 [==============================] - 1s 45ms/step - loss: 0.0028 - accuracy: 0.0208 - val_loss: 0.0028 - val_accuracy: 0.0110\n",
            "Epoch 346/1000\n",
            "29/29 [==============================] - 1s 38ms/step - loss: 0.0028 - accuracy: 0.0198 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 347/1000\n",
            "29/29 [==============================] - 1s 39ms/step - loss: 0.0028 - accuracy: 0.0204 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 348/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.0207 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 349/1000\n",
            "29/29 [==============================] - 1s 34ms/step - loss: 0.0028 - accuracy: 0.0212 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 350/1000\n",
            "29/29 [==============================] - 1s 32ms/step - loss: 0.0028 - accuracy: 0.0221 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 351/1000\n",
            "29/29 [==============================] - 1s 34ms/step - loss: 0.0028 - accuracy: 0.0209 - val_loss: 0.0028 - val_accuracy: 0.0124\n",
            "Epoch 352/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.0202 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 353/1000\n",
            "29/29 [==============================] - 1s 30ms/step - loss: 0.0028 - accuracy: 0.0197 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 354/1000\n",
            "29/29 [==============================] - 1s 31ms/step - loss: 0.0028 - accuracy: 0.0212 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 355/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0028 - accuracy: 0.0203 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 356/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0029 - accuracy: 0.0215 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 357/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.0224 - val_loss: 0.0028 - val_accuracy: 0.0118\n",
            "Epoch 358/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.0208 - val_loss: 0.0028 - val_accuracy: 0.0159\n",
            "Epoch 359/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.0219 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 360/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.0229 - val_loss: 0.0028 - val_accuracy: 0.0114\n",
            "Epoch 361/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0028 - accuracy: 0.0210 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 362/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0218 - val_loss: 0.0028 - val_accuracy: 0.0167\n",
            "Epoch 363/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0218 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 364/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0221 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 365/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0028 - accuracy: 0.0219 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 366/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.0195 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 367/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.0212 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 368/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0028 - accuracy: 0.0214 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 369/1000\n",
            "29/29 [==============================] - 1s 32ms/step - loss: 0.0028 - accuracy: 0.0217 - val_loss: 0.0028 - val_accuracy: 0.0152\n",
            "Epoch 370/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.0218 - val_loss: 0.0028 - val_accuracy: 0.0152\n",
            "Epoch 371/1000\n",
            "29/29 [==============================] - 1s 37ms/step - loss: 0.0028 - accuracy: 0.0214 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 372/1000\n",
            "29/29 [==============================] - 1s 31ms/step - loss: 0.0028 - accuracy: 0.0204 - val_loss: 0.0029 - val_accuracy: 0.0165\n",
            "Epoch 373/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.0228 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 374/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.0231 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 375/1000\n",
            "29/29 [==============================] - 1s 32ms/step - loss: 0.0028 - accuracy: 0.0241 - val_loss: 0.0028 - val_accuracy: 0.0120\n",
            "Epoch 376/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.0217 - val_loss: 0.0028 - val_accuracy: 0.0116\n",
            "Epoch 377/1000\n",
            "29/29 [==============================] - 1s 30ms/step - loss: 0.0028 - accuracy: 0.0215 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 378/1000\n",
            "29/29 [==============================] - 1s 30ms/step - loss: 0.0028 - accuracy: 0.0214 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 379/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.0228 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 380/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.0215 - val_loss: 0.0028 - val_accuracy: 0.0159\n",
            "Epoch 381/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.0228 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 382/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0219 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 383/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.0230 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 384/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.0218 - val_loss: 0.0028 - val_accuracy: 0.0112\n",
            "Epoch 385/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0028 - accuracy: 0.0217 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 386/1000\n",
            "29/29 [==============================] - 1s 32ms/step - loss: 0.0028 - accuracy: 0.0220 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 387/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0214 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 388/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0029 - accuracy: 0.0214 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 389/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0233 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 390/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.0230 - val_loss: 0.0028 - val_accuracy: 0.0124\n",
            "Epoch 391/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.0246 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 392/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.0233 - val_loss: 0.0028 - val_accuracy: 0.0104\n",
            "Epoch 393/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.0229 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 394/1000\n",
            "29/29 [==============================] - 1s 34ms/step - loss: 0.0028 - accuracy: 0.0222 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 395/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.0229 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 396/1000\n",
            "29/29 [==============================] - 1s 36ms/step - loss: 0.0028 - accuracy: 0.0231 - val_loss: 0.0028 - val_accuracy: 0.0175\n",
            "Epoch 397/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.0233 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 398/1000\n",
            "29/29 [==============================] - 1s 31ms/step - loss: 0.0028 - accuracy: 0.0231 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 399/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.0240 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 400/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0028 - accuracy: 0.0224 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 401/1000\n",
            "29/29 [==============================] - 1s 37ms/step - loss: 0.0028 - accuracy: 0.0212 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 402/1000\n",
            "29/29 [==============================] - 1s 32ms/step - loss: 0.0028 - accuracy: 0.0235 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 403/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0028 - accuracy: 0.0247 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 404/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0230 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 405/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0234 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 406/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0241 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 407/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0222 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 408/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0243 - val_loss: 0.0028 - val_accuracy: 0.0124\n",
            "Epoch 409/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0028 - accuracy: 0.0240 - val_loss: 0.0028 - val_accuracy: 0.0120\n",
            "Epoch 410/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0028 - accuracy: 0.0243 - val_loss: 0.0028 - val_accuracy: 0.0114\n",
            "Epoch 411/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0028 - accuracy: 0.0234 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 412/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0028 - accuracy: 0.0235 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 413/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0215 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 414/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0028 - accuracy: 0.0243 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 415/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0028 - accuracy: 0.0234 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 416/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.0251 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 417/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0028 - accuracy: 0.0250 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 418/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0238 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 419/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0028 - accuracy: 0.0222 - val_loss: 0.0028 - val_accuracy: 0.0110\n",
            "Epoch 420/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0218 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 421/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0241 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 422/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0239 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 423/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0236 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 424/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0232 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 425/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0229 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 426/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0244 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 427/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0255 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 428/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0028 - accuracy: 0.0234 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 429/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0237 - val_loss: 0.0028 - val_accuracy: 0.0120\n",
            "Epoch 430/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0240 - val_loss: 0.0028 - val_accuracy: 0.0112\n",
            "Epoch 431/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0236 - val_loss: 0.0028 - val_accuracy: 0.0124\n",
            "Epoch 432/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0238 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 433/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.0249 - val_loss: 0.0028 - val_accuracy: 0.0159\n",
            "Epoch 434/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0028 - accuracy: 0.0240 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 435/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0234 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 436/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0239 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 437/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0259 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 438/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0233 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 439/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0028 - accuracy: 0.0253 - val_loss: 0.0028 - val_accuracy: 0.0118\n",
            "Epoch 440/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0028 - accuracy: 0.0237 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 441/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0028 - accuracy: 0.0240 - val_loss: 0.0028 - val_accuracy: 0.0106\n",
            "Epoch 442/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0249 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 443/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0256 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 444/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.0252 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 445/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0252 - val_loss: 0.0028 - val_accuracy: 0.0116\n",
            "Epoch 446/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0228 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 447/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0260 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 448/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0243 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 449/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0259 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 450/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.0250 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 451/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.0251 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 452/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.0252 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 453/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.0265 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 454/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.0257 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 455/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.0254 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 456/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0028 - accuracy: 0.0256 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 457/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.0238 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 458/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0028 - accuracy: 0.0264 - val_loss: 0.0028 - val_accuracy: 0.0110\n",
            "Epoch 459/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.0258 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 460/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.0268 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 461/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.0234 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 462/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0265 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 463/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0268 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 464/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.0259 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 465/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.0256 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 466/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.0236 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 467/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.0263 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 468/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.0246 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 469/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0266 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 470/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0028 - accuracy: 0.0268 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 471/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0028 - accuracy: 0.0257 - val_loss: 0.0028 - val_accuracy: 0.0152\n",
            "Epoch 472/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0286 - val_loss: 0.0028 - val_accuracy: 0.0155\n",
            "Epoch 473/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0267 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 474/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0265 - val_loss: 0.0028 - val_accuracy: 0.0116\n",
            "Epoch 475/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0262 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 476/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0260 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 477/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0248 - val_loss: 0.0028 - val_accuracy: 0.0118\n",
            "Epoch 478/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0028 - accuracy: 0.0280 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 479/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0028 - accuracy: 0.0269 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 480/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0269 - val_loss: 0.0028 - val_accuracy: 0.0116\n",
            "Epoch 481/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0028 - accuracy: 0.0277 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 482/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0028 - accuracy: 0.0270 - val_loss: 0.0028 - val_accuracy: 0.0175\n",
            "Epoch 483/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.0259 - val_loss: 0.0028 - val_accuracy: 0.0155\n",
            "Epoch 484/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0271 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 485/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.0251 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 486/1000\n",
            "29/29 [==============================] - 1s 31ms/step - loss: 0.0028 - accuracy: 0.0261 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 487/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0028 - accuracy: 0.0265 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 488/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.0292 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 489/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.0281 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 490/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0269 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 491/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0028 - accuracy: 0.0271 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 492/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0028 - accuracy: 0.0265 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 493/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0259 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 494/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0271 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 495/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0275 - val_loss: 0.0028 - val_accuracy: 0.0110\n",
            "Epoch 496/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0267 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 497/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0272 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 498/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0265 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 499/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0270 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 500/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0254 - val_loss: 0.0028 - val_accuracy: 0.0106\n",
            "Epoch 501/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0262 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 502/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0268 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 503/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0280 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 504/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0283 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 505/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0274 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 506/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0261 - val_loss: 0.0028 - val_accuracy: 0.0114\n",
            "Epoch 507/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0267 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 508/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0262 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 509/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0300 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 510/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0265 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 511/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0284 - val_loss: 0.0028 - val_accuracy: 0.0112\n",
            "Epoch 512/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0265 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 513/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0276 - val_loss: 0.0028 - val_accuracy: 0.0116\n",
            "Epoch 514/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0027 - accuracy: 0.0288 - val_loss: 0.0028 - val_accuracy: 0.0114\n",
            "Epoch 515/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0291 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 516/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0278 - val_loss: 0.0028 - val_accuracy: 0.0124\n",
            "Epoch 517/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0300 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 518/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0290 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 519/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0285 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 520/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0277 - val_loss: 0.0028 - val_accuracy: 0.0155\n",
            "Epoch 521/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0278 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 522/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0267 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 523/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0287 - val_loss: 0.0028 - val_accuracy: 0.0161\n",
            "Epoch 524/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0270 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 525/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0287 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 526/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0266 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 527/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0289 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 528/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0281 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 529/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0290 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 530/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0272 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 531/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0292 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 532/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0279 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 533/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0283 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 534/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0281 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 535/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0271 - val_loss: 0.0028 - val_accuracy: 0.0124\n",
            "Epoch 536/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0264 - val_loss: 0.0028 - val_accuracy: 0.0161\n",
            "Epoch 537/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0302 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 538/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0291 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 539/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0285 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 540/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0288 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 541/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0294 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 542/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0302 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 543/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0304 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 544/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0282 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 545/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0028 - accuracy: 0.0285 - val_loss: 0.0031 - val_accuracy: 0.0108\n",
            "Epoch 546/1000\n",
            "29/29 [==============================] - 1s 41ms/step - loss: 0.0028 - accuracy: 0.0274 - val_loss: 0.0028 - val_accuracy: 0.0171\n",
            "Epoch 547/1000\n",
            "29/29 [==============================] - 1s 39ms/step - loss: 0.0027 - accuracy: 0.0289 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 548/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0289 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 549/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0286 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 550/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0298 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 551/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0276 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 552/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0289 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 553/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0289 - val_loss: 0.0028 - val_accuracy: 0.0152\n",
            "Epoch 554/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0303 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 555/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0295 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 556/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0317 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 557/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0294 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 558/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0289 - val_loss: 0.0028 - val_accuracy: 0.0159\n",
            "Epoch 559/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0297 - val_loss: 0.0028 - val_accuracy: 0.0124\n",
            "Epoch 560/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0302 - val_loss: 0.0029 - val_accuracy: 0.0165\n",
            "Epoch 561/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0289 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 562/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0297 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 563/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0304 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 564/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0277 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 565/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0304 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 566/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0307 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 567/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0314 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 568/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0301 - val_loss: 0.0028 - val_accuracy: 0.0124\n",
            "Epoch 569/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0309 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 570/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0300 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 571/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0298 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 572/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0286 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 573/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0291 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 574/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0303 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 575/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0291 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 576/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0310 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 577/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.0315 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 578/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0299 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 579/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.0323 - val_loss: 0.0029 - val_accuracy: 0.0106\n",
            "Epoch 580/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0293 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 581/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0297 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 582/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.0312 - val_loss: 0.0028 - val_accuracy: 0.0124\n",
            "Epoch 583/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0312 - val_loss: 0.0028 - val_accuracy: 0.0118\n",
            "Epoch 584/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0308 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 585/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0292 - val_loss: 0.0028 - val_accuracy: 0.0116\n",
            "Epoch 586/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0324 - val_loss: 0.0028 - val_accuracy: 0.0120\n",
            "Epoch 587/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0306 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 588/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0302 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 589/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0310 - val_loss: 0.0028 - val_accuracy: 0.0159\n",
            "Epoch 590/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0303 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 591/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0303 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 592/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0305 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 593/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0314 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 594/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0309 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 595/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0031 - accuracy: 0.0256 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 596/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0027 - accuracy: 0.0311 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 597/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0027 - accuracy: 0.0337 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 598/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.0318 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 599/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0323 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 600/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0319 - val_loss: 0.0028 - val_accuracy: 0.0171\n",
            "Epoch 601/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0304 - val_loss: 0.0028 - val_accuracy: 0.0112\n",
            "Epoch 602/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0322 - val_loss: 0.0028 - val_accuracy: 0.0116\n",
            "Epoch 603/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0317 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 604/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0326 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 605/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0316 - val_loss: 0.0028 - val_accuracy: 0.0110\n",
            "Epoch 606/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0318 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 607/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0305 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 608/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0322 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 609/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0316 - val_loss: 0.0028 - val_accuracy: 0.0124\n",
            "Epoch 610/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0314 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 611/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0337 - val_loss: 0.0028 - val_accuracy: 0.0152\n",
            "Epoch 612/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.0310 - val_loss: 0.0028 - val_accuracy: 0.0124\n",
            "Epoch 613/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0324 - val_loss: 0.0028 - val_accuracy: 0.0120\n",
            "Epoch 614/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0310 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 615/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0315 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 616/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0334 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 617/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0305 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 618/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0331 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 619/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0331 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 620/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0027 - accuracy: 0.0332 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 621/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0340 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 622/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0322 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 623/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0327 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 624/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0318 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 625/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.0341 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 626/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.0322 - val_loss: 0.0028 - val_accuracy: 0.0124\n",
            "Epoch 627/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0333 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 628/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0350 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 629/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0323 - val_loss: 0.0028 - val_accuracy: 0.0161\n",
            "Epoch 630/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0326 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 631/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0335 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 632/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0333 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 633/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0330 - val_loss: 0.0028 - val_accuracy: 0.0155\n",
            "Epoch 634/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0336 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 635/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0308 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 636/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0332 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 637/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0343 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 638/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0324 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 639/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0331 - val_loss: 0.0028 - val_accuracy: 0.0124\n",
            "Epoch 640/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0314 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 641/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0331 - val_loss: 0.0029 - val_accuracy: 0.0163\n",
            "Epoch 642/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0314 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 643/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0345 - val_loss: 0.0028 - val_accuracy: 0.0110\n",
            "Epoch 644/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0322 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 645/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0343 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 646/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0322 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 647/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0333 - val_loss: 0.0028 - val_accuracy: 0.0112\n",
            "Epoch 648/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.0331 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 649/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0337 - val_loss: 0.0028 - val_accuracy: 0.0114\n",
            "Epoch 650/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0334 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 651/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.0329 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 652/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0027 - accuracy: 0.0330 - val_loss: 0.0029 - val_accuracy: 0.0102\n",
            "Epoch 653/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0310 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 654/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0340 - val_loss: 0.0029 - val_accuracy: 0.0104\n",
            "Epoch 655/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0027 - accuracy: 0.0359 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 656/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0343 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 657/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0027 - accuracy: 0.0334 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 658/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0345 - val_loss: 0.0029 - val_accuracy: 0.0110\n",
            "Epoch 659/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0343 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 660/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0347 - val_loss: 0.0029 - val_accuracy: 0.0112\n",
            "Epoch 661/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0333 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 662/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0335 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 663/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0343 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 664/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0354 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 665/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0357 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 666/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0334 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 667/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0347 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 668/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0342 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 669/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0342 - val_loss: 0.0029 - val_accuracy: 0.0100\n",
            "Epoch 670/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0340 - val_loss: 0.0028 - val_accuracy: 0.0112\n",
            "Epoch 671/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0341 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 672/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0331 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 673/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0359 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 674/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0358 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 675/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0340 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 676/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0338 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 677/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0343 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 678/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0335 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 679/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0347 - val_loss: 0.0029 - val_accuracy: 0.0085\n",
            "Epoch 680/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.0352 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 681/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0345 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 682/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.0342 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 683/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0342 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 684/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.0342 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 685/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0369 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 686/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0345 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 687/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0352 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 688/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0361 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 689/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0357 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 690/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0027 - accuracy: 0.0344 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 691/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0365 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 692/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0339 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 693/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0354 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 694/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0346 - val_loss: 0.0029 - val_accuracy: 0.0112\n",
            "Epoch 695/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0362 - val_loss: 0.0029 - val_accuracy: 0.0116\n",
            "Epoch 696/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0360 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 697/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0358 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 698/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0352 - val_loss: 0.0029 - val_accuracy: 0.0116\n",
            "Epoch 699/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0357 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 700/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0346 - val_loss: 0.0029 - val_accuracy: 0.0112\n",
            "Epoch 701/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0350 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 702/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0370 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 703/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0357 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 704/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0359 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 705/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0366 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 706/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0336 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 707/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0378 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 708/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0371 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 709/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0358 - val_loss: 0.0029 - val_accuracy: 0.0108\n",
            "Epoch 710/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0347 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 711/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0344 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 712/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0362 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 713/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0361 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 714/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0350 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 715/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0369 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 716/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0356 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 717/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0359 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 718/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0363 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 719/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0352 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 720/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0371 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 721/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0370 - val_loss: 0.0030 - val_accuracy: 0.0118\n",
            "Epoch 722/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0027 - accuracy: 0.0357 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 723/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0372 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 724/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0377 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 725/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0381 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 726/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0367 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 727/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0371 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 728/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0373 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 729/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0359 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 730/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0376 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 731/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0353 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 732/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0364 - val_loss: 0.0029 - val_accuracy: 0.0112\n",
            "Epoch 733/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0385 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 734/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0378 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 735/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0382 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 736/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0368 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 737/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0349 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 738/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0364 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 739/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0353 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 740/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0364 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 741/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0357 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 742/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0357 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 743/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0369 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 744/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0374 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 745/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0377 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 746/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0355 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 747/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0373 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 748/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0027 - accuracy: 0.0367 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 749/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 0.0027 - accuracy: 0.0359 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 750/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0387 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 751/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0364 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 752/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0375 - val_loss: 0.0029 - val_accuracy: 0.0116\n",
            "Epoch 753/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0377 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 754/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0350 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 755/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0360 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 756/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0362 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 757/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0355 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 758/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0358 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 759/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0375 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 760/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0374 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 761/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0399 - val_loss: 0.0029 - val_accuracy: 0.0100\n",
            "Epoch 762/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0355 - val_loss: 0.0029 - val_accuracy: 0.0104\n",
            "Epoch 763/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0377 - val_loss: 0.0029 - val_accuracy: 0.0110\n",
            "Epoch 764/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0368 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 765/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0375 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 766/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0382 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 767/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0398 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 768/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0360 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 769/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0390 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 770/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0374 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 771/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0373 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 772/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0393 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 773/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0399 - val_loss: 0.0029 - val_accuracy: 0.0112\n",
            "Epoch 774/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0375 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 775/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0378 - val_loss: 0.0029 - val_accuracy: 0.0106\n",
            "Epoch 776/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0375 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 777/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0369 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 778/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0368 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 779/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0378 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 780/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0387 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 781/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0373 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 782/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0382 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 783/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0374 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 784/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0386 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 785/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0372 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 786/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0381 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 787/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0383 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 788/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0376 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 789/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0389 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 790/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0026 - accuracy: 0.0397 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 791/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0379 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 792/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.0379 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 793/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0389 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 794/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0384 - val_loss: 0.0029 - val_accuracy: 0.0165\n",
            "Epoch 795/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0367 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 796/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0392 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 797/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0375 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 798/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0366 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 799/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0382 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 800/1000\n",
            "29/29 [==============================] - 1s 42ms/step - loss: 0.0027 - accuracy: 0.0386 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 801/1000\n",
            "29/29 [==============================] - 1s 39ms/step - loss: 0.0027 - accuracy: 0.0367 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 802/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0027 - accuracy: 0.0390 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 803/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0354 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 804/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0385 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 805/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0385 - val_loss: 0.0029 - val_accuracy: 0.0116\n",
            "Epoch 806/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0396 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 807/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0373 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 808/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0362 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 809/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0399 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 810/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0026 - accuracy: 0.0384 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 811/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0372 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 812/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0368 - val_loss: 0.0029 - val_accuracy: 0.0116\n",
            "Epoch 813/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0380 - val_loss: 0.0029 - val_accuracy: 0.0100\n",
            "Epoch 814/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0376 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 815/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0362 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 816/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0396 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 817/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0377 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 818/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0395 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 819/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0026 - accuracy: 0.0390 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 820/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0402 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 821/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0379 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 822/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0384 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 823/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0376 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 824/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0391 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 825/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0371 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 826/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0387 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 827/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0367 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 828/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0391 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 829/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0393 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 830/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0395 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 831/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0405 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 832/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0385 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 833/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0402 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 834/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0388 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 835/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0387 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 836/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0394 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 837/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0368 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 838/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0381 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 839/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0374 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 840/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0391 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 841/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0383 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 842/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0393 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 843/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0391 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 844/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0394 - val_loss: 0.0030 - val_accuracy: 0.0153\n",
            "Epoch 845/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0397 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 846/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0379 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 847/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0399 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 848/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0391 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 849/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0411 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 850/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0400 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 851/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0399 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 852/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0392 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 853/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0392 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 854/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0392 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 855/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0405 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 856/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0404 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 857/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0392 - val_loss: 0.0029 - val_accuracy: 0.0161\n",
            "Epoch 858/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0408 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 859/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0389 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 860/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0388 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 861/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0388 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 862/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0420 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 863/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0402 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 864/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0026 - accuracy: 0.0400 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 865/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0395 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 866/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0404 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 867/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0375 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 868/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0379 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 869/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0392 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 870/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0386 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 871/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0397 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 872/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0389 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 873/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0026 - accuracy: 0.0391 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 874/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0402 - val_loss: 0.0029 - val_accuracy: 0.0112\n",
            "Epoch 875/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0385 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 876/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0389 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 877/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0416 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 878/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0406 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 879/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0412 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 880/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0396 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 881/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0378 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 882/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0026 - accuracy: 0.0407 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 883/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0396 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 884/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0379 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 885/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0421 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 886/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0394 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 887/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0409 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 888/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0404 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 889/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0400 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 890/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0425 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 891/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0393 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 892/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0408 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 893/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0396 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 894/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0402 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 895/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0026 - accuracy: 0.0391 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 896/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0393 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 897/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0397 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 898/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0404 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 899/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0026 - accuracy: 0.0417 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 900/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0379 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 901/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0409 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 902/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0407 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 903/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0409 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 904/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0409 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 905/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0026 - accuracy: 0.0403 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 906/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0411 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 907/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0026 - accuracy: 0.0391 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 908/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0407 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 909/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0402 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 910/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0406 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 911/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0406 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 912/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0407 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 913/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0407 - val_loss: 0.0059 - val_accuracy: 0.0081\n",
            "Epoch 914/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0035 - accuracy: 0.0191 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 915/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0318 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 916/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0354 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 917/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0387 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 918/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0395 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 919/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0408 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 920/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0403 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 921/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0397 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 922/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0414 - val_loss: 0.0029 - val_accuracy: 0.0106\n",
            "Epoch 923/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0413 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 924/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0417 - val_loss: 0.0029 - val_accuracy: 0.0092\n",
            "Epoch 925/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0413 - val_loss: 0.0029 - val_accuracy: 0.0116\n",
            "Epoch 926/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0421 - val_loss: 0.0029 - val_accuracy: 0.0102\n",
            "Epoch 927/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0401 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 928/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0410 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 929/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0417 - val_loss: 0.0029 - val_accuracy: 0.0106\n",
            "Epoch 930/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0430 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 931/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0408 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 932/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0413 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 933/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0415 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 934/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0414 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 935/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0398 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 936/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0405 - val_loss: 0.0029 - val_accuracy: 0.0108\n",
            "Epoch 937/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0422 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 938/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0401 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 939/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0026 - accuracy: 0.0418 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 940/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0406 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 941/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0430 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 942/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0424 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 943/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0428 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 944/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0420 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 945/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0026 - accuracy: 0.0442 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 946/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0415 - val_loss: 0.0029 - val_accuracy: 0.0112\n",
            "Epoch 947/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0430 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 948/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0399 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 949/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0414 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 950/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0405 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 951/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0423 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 952/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0423 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 953/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0419 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 954/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0407 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 955/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0414 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 956/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0396 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 957/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0427 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 958/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0419 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 959/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0410 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 960/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0388 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 961/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0431 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 962/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0418 - val_loss: 0.0029 - val_accuracy: 0.0116\n",
            "Epoch 963/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0420 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 964/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0420 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 965/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0426 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 966/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0430 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 967/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0425 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 968/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0432 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 969/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0419 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 970/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0438 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 971/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0426 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 972/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0418 - val_loss: 0.0029 - val_accuracy: 0.0161\n",
            "Epoch 973/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0026 - accuracy: 0.0430 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 974/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0026 - accuracy: 0.0413 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 975/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0026 - accuracy: 0.0441 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 976/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0420 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 977/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0426 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 978/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0428 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 979/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0449 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 980/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0026 - accuracy: 0.0419 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 981/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0420 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 982/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0413 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 983/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0417 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 984/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0414 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 985/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0418 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 986/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0453 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 987/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0410 - val_loss: 0.0029 - val_accuracy: 0.0112\n",
            "Epoch 988/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0413 - val_loss: 0.0029 - val_accuracy: 0.0112\n",
            "Epoch 989/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0438 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 990/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0423 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 991/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0409 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 992/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0425 - val_loss: 0.0029 - val_accuracy: 0.0116\n",
            "Epoch 993/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0412 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 994/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0414 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 995/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0426 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 996/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0411 - val_loss: 0.0029 - val_accuracy: 0.0116\n",
            "Epoch 997/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0422 - val_loss: 0.0029 - val_accuracy: 0.0102\n",
            "Epoch 998/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0442 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 999/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0433 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 1000/1000\n",
            "29/29 [==============================] - 1s 31ms/step - loss: 0.0026 - accuracy: 0.0430 - val_loss: 0.0029 - val_accuracy: 0.0148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Unicamp/23.2/DL para sintese de sinais/Projetos computacionais/A1 - Projeto Final/Códigos/modelo salvo/'\n",
        "# Salvar o modelo\n",
        "vae.save(path+'modelo_vae')\n",
        "# Salvar os pesos\n",
        "vae.save_weights(path+'modelo_vae/pesos_vae')"
      ],
      "metadata": {
        "id": "QtYtwvIuj541"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss curves\n",
        "plt.plot(history.history['loss'], label=\"loss\")\n",
        "plt.plot(history.history['val_loss'], label=\"val_loss\")\n",
        "plt.title('loss curves')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "sFw-jnbiYm7A",
        "outputId": "0e085bd7-524b-43d0-f8cf-e3b8b09ca563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Val curves\n",
        "plt.plot(history.history['accuracy'],label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'],label='val_accuracy')\n",
        "plt.title('val curves')\n",
        "plt.ylabel('Validation')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "bhMzr79x5tF8",
        "outputId": "e1a4f430-88e6-4055-a0b0-4f907b1323a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Espaço latente para os dados reais"
      ],
      "metadata": {
        "id": "jAsNIvdbhtcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D plot of the classes in latent space\n",
        "latent_space, _, _ = encoder.predict(X_test,batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grkd64h6Ypyb",
        "outputId": "c5a45b1b-ce51-4d92-a257-2c3552a66fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar K-means\n",
        "num_clusters = 4  # Número de clusters igual ao número de labels\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "cluster_labels = kmeans.fit_predict(latent_space)\n",
        "\n",
        "reducer = umap.UMAP(n_neighbors=10,min_dist=0.5) #50 e 0.5\n",
        "embedding = reducer.fit_transform(latent_space)\n",
        "\n",
        "# Visualizar UMAP\n",
        "import plotly.express as px\n",
        "proj = pd.DataFrame(embedding)\n",
        "proj.columns = [\"componente_1\", \"componente_2\"]\n",
        "proj[\"labels\"] = y_train[:231]\n",
        "fig = px.scatter(proj, x='componente_1', y='componente_2', color = cluster_labels, width=800, title = 'Representação do espaço latente - Dados Reais')\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "PV5HjGK1bbY7",
        "outputId": "977fd4ef-1799-4f88-daca-e4faf86ddd1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"86140af4-bc7f-4dfc-8167-de3c29916021\" class=\"plotly-graph-div\" style=\"height:525px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"86140af4-bc7f-4dfc-8167-de3c29916021\")) {                    Plotly.newPlot(                        \"86140af4-bc7f-4dfc-8167-de3c29916021\",                        [{\"hovertemplate\":\"componente_1=%{x}\\u003cbr\\u003ecomponente_2=%{y}\\u003cbr\\u003ecolor=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[0,3,2,0,1,1,3,0,0,0,1,3,3,1,2,0,3,1,3,1,0,0,0,0,1,3,0,0,1,3,0,1,0,1,0,2,1,3,0,3,1,3,2,1,3,0,1,1,3,2,0,3,1,3,0,3,0,2,2,0,1,2,3,2,1,1,0,2,3,0,1,3,0,1,1,0,3,1,1,0,1,0,0,1,2,2,1,2,1,0,2,2,3,3,1,0,3,3,1,1,0,3,3,0,3,1,0,1,2,0,3,3,1,3,0,0,0,2,0,1,0,1,3,2,1,2,3,3,0,3,0,0,0,3,2,1,3,0,0,3,3,1,1,0,2,3,3,2,2,1,0,0,0,1,1,0,2,3,2,1,3,0,0,2,1,2,1,3,1,3,3,0,3,0,1,3,3,3,1,1,0,0,1,0,0,0,3,1,0,0,2,3,1,1,3,1,3,1,0,3,1,3,0,2,0,2,1,0,3,0,3,0,1,0,3,1,3,2,0,0,2,0,0,3,0,0,0,3,0,0,3],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[7.173338413238525,4.7208027839660645,11.924297332763672,8.41605281829834,10.345901489257812,7.876764297485352,0.8275004029273987,8.799574851989746,10.314794540405273,8.750619888305664,5.544773578643799,3.700456380844116,1.8876361846923828,6.178993225097656,11.052787780761719,6.477769374847412,3.1456081867218018,8.030959129333496,0.421874076128006,7.812326908111572,10.4673433303833,9.711869239807129,7.817773818969727,8.201940536499023,8.34096908569336,2.2792325019836426,5.442576885223389,5.94818639755249,6.936178207397461,2.379149913787842,4.829836368560791,9.144704818725586,8.211237907409668,8.078322410583496,8.199339866638184,9.252394676208496,4.531284809112549,3.6487514972686768,8.117105484008789,4.497527599334717,8.017812728881836,4.337412357330322,10.959277153015137,4.8642354011535645,4.840294361114502,8.715185165405273,6.326255798339844,9.390458106994629,-0.06952103972434998,11.271788597106934,9.935731887817383,0.7245194315910339,5.991732597351074,2.920825242996216,4.0273027420043945,3.472867727279663,10.912657737731934,12.198027610778809,11.13196086883545,8.305423736572266,4.778407096862793,12.066997528076172,0.4363461434841156,11.28093433380127,7.356494426727295,6.039641380310059,6.361562252044678,12.17308521270752,1.5300859212875366,5.312327861785889,6.599724292755127,4.895590305328369,7.817811012268066,5.89066219329834,8.864907264709473,7.926180362701416,4.12140417098999,9.590344429016113,9.259202003479004,6.131919860839844,5.288179874420166,9.014601707458496,5.310245037078857,7.121959209442139,10.77427864074707,11.177398681640625,4.8409037590026855,10.889610290527344,7.651360511779785,8.99725341796875,10.617101669311523,11.581235885620117,0.036921754479408264,2.0429110527038574,4.615067958831787,11.112340927124023,0.18723765015602112,1.2560211420059204,9.427263259887695,5.227726459503174,6.341271877288818,1.2659014463424683,0.042280782014131546,8.681937217712402,4.285865306854248,6.065154075622559,10.908763885498047,10.521127700805664,11.196492195129395,10.59205150604248,1.3090647459030151,0.683036208152771,8.433392524719238,1.994801640510559,5.552579879760742,6.660191059112549,3.9993011951446533,10.371384620666504,7.470368385314941,8.778472900390625,8.848404884338379,10.789261817932129,1.5559329986572266,9.585180282592773,6.75706148147583,9.538098335266113,3.9365968704223633,1.3532322645187378,6.766783714294434,0.286620557308197,8.85712718963623,9.322436332702637,9.029394149780273,4.8438401222229,11.459775924682617,10.242423057556152,0.020420623943209648,8.451162338256836,8.43212890625,2.4139108657836914,3.294250726699829,9.834019660949707,6.816864490509033,8.731084823608398,11.46293830871582,4.535715579986572,2.690837860107422,11.118917465209961,8.79970645904541,9.489663124084473,3.691622495651245,8.71988296508789,9.376540184020996,8.504593849182129,6.328273773193359,10.152782440185547,9.169855117797852,4.13838005065918,11.103864669799805,5.058476448059082,2.4393515586853027,5.800177574157715,4.751976490020752,11.294846534729004,8.076985359191895,9.934450149536133,3.9455490112304688,4.528683662414551,5.744008541107178,4.370789051055908,2.15609073638916,4.098421096801758,2.166377067565918,7.953331470489502,9.14001178741455,0.9759674072265625,0.1303347796201706,2.581242799758911,8.23847770690918,5.926863670349121,3.9902169704437256,9.54050350189209,10.603965759277344,6.030646800994873,5.063216686248779,10.329056739807129,0.2535002827644348,8.775659561157227,6.094066619873047,9.767757415771484,10.0641450881958,0.24557995796203613,5.156285762786865,7.193364143371582,-0.10629451274871826,6.802352428436279,2.3836452960968018,7.288228511810303,8.991259574890137,2.501293182373047,10.711837768554688,1.7664874792099,7.972504138946533,11.751483917236328,8.486888885498047,11.6777925491333,10.857179641723633,4.425542831420898,1.9570670127868652,9.346269607543945,3.6227002143859863,9.27616024017334,7.550943374633789,3.922135829925537,0.33101940155029297,7.01703405380249,2.160599708557129,10.52249526977539,6.353644371032715,7.481734275817871,11.757328987121582,10.862306594848633,4.339616298675537,2.174525260925293,7.442211151123047,4.010427951812744,4.556981086730957,0.7825179696083069,5.398813247680664,5.283878326416016,3.130481719970703],\"xaxis\":\"x\",\"y\":[7.150887966156006,4.348745822906494,3.3913917541503906,9.253483772277832,-0.010484056547284126,-0.6726418137550354,1.4566031694412231,9.317124366760254,7.3364481925964355,7.402151584625244,0.5543983578681946,-0.16667403280735016,4.1343255043029785,1.9397038221359253,4.615212440490723,4.6139302253723145,4.823544979095459,0.24116501212120056,3.2899458408355713,0.4427259862422943,7.693294525146484,7.968539237976074,8.984153747558594,9.661200523376465,1.1819970607757568,1.9648913145065308,6.8143110275268555,6.592159748077393,-0.09020764380693436,1.6385993957519531,4.958508491516113,-0.5975450873374939,7.143752574920654,1.0461335182189941,9.678261756896973,3.4940788745880127,-0.2576710283756256,2.907832384109497,7.393697738647461,3.2161264419555664,1.056164264678955,2.7225682735443115,0.8470008373260498,-0.6354422569274902,1.9256991147994995,6.615072250366211,-0.09008119255304337,-1.3400332927703857,1.8703917264938354,2.0501530170440674,8.50444221496582,3.4572858810424805,0.16510939598083496,2.7845699787139893,8.111018180847168,-0.06491146236658096,6.65505838394165,4.146975040435791,1.8915146589279175,9.986052513122559,0.32635799050331116,3.99569034576416,1.3112354278564453,5.677778244018555,1.7186486721038818,-0.5615322589874268,4.217670917510986,3.3664443492889404,4.597512722015381,4.80195951461792,-0.8819913268089294,4.455775260925293,8.577072143554688,2.258408546447754,-1.0721157789230347,9.19916820526123,3.1209027767181396,-0.4048500955104828,-1.6180968284606934,6.10711669921875,1.4482872486114502,4.595921993255615,6.726019382476807,-0.4762742817401886,5.370852470397949,3.228410482406616,0.8837816119194031,2.9806294441223145,1.0115153789520264,5.945051193237305,3.4186198711395264,4.168672561645508,3.433680295944214,4.945608139038086,0.7866379022598267,6.390054225921631,2.2186379432678223,3.008655071258545,-1.3950788974761963,0.9379785060882568,6.570399284362793,4.686882495880127,1.4798356294631958,8.965534210205078,4.707956790924072,1.9101394414901733,7.0903239250183105,-0.5225683450698853,3.566473960876465,7.425757884979248,1.1263214349746704,1.0477081537246704,2.4254655838012695,3.7806663513183594,5.578863620758057,4.354100704193115,7.724583148956299,5.359244346618652,7.813678741455078,-0.9950522780418396,4.21082878112793,-0.07721119374036789,2.927093029022217,3.375797748565674,-0.3509884178638458,2.9459280967712402,3.126438617706299,4.944121360778809,7.148162364959717,3.7488110065460205,5.2341837882995605,6.909080505371094,9.456949234008789,3.596710205078125,3.133744478225708,0.1708841621875763,3.9760994911193848,6.947584629058838,4.171709060668945,2.602273464202881,0.24435463547706604,-0.3531937003135681,0.65296870470047,10.032923698425293,4.573863983154297,3.294016122817993,2.0157320499420166,0.5676984786987305,3.325042486190796,-1.0472334623336792,8.244401931762695,9.900808334350586,7.448698043823242,2.8277804851531982,2.1302804946899414,7.490123271942139,3.1468119621276855,2.2420380115509033,4.987417221069336,1.1347393989562988,3.601161479949951,6.374075412750244,7.06406831741333,2.277139902114868,1.9224824905395508,3.117509365081787,-0.2839181125164032,1.7574981451034546,-0.3063361942768097,3.6237611770629883,4.050189018249512,8.287186622619629,3.553412675857544,9.234683990478516,-0.9168331623077393,3.6634340286254883,1.1538560390472412,4.427063941955566,0.7423275113105774,1.5877764225006104,6.80806303024292,8.564570426940918,0.2161685973405838,4.721662521362305,5.3084588050842285,5.741087913513184,0.8473866581916809,-1.2736365795135498,6.908195495605469,8.306201934814453,5.407130718231201,4.304496765136719,0.12662893533706665,0.8055895566940308,1.2318494319915771,1.4134403467178345,4.261555194854736,1.1048754453659058,7.464914798736572,5.1080002784729,0.11942198127508163,1.9167195558547974,6.894506454467773,3.5487473011016846,6.505690097808838,5.349253177642822,-0.15370948612689972,5.007568836212158,2.567622184753418,5.3867950439453125,0.40733182430267334,5.0433735847473145,-0.5656393766403198,8.23687744140625,1.4589128494262695,1.5069247484207153,4.851011276245117,2.9903879165649414,3.993648052215576,8.153986930847168,2.6371922492980957,6.24041748046875,7.612339973449707,3.156756639480591,8.640933990478516,7.955273628234863,7.352297306060791,3.940124750137329,4.608273983001709,7.06418514251709,-0.09941569715738297],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"componente_1\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"componente_2\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"color\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Representa\\u00e7\\u00e3o do espa\\u00e7o latente - Dados Reais\"},\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('86140af4-bc7f-4dfc-8167-de3c29916021');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}