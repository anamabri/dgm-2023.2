{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d632c8d-789f-47fd-a7cd-cc2db8853459",
   "metadata": {
    "id": "7d632c8d-789f-47fd-a7cd-cc2db8853459"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e63aaedc-83f1-4843-a47b-7fd402a4b31d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "executionInfo": {
     "elapsed": 241,
     "status": "error",
     "timestamp": 1697481957249,
     "user": {
      "displayName": "Larissa Rangel de Azevedo",
      "userId": "11239044081097926538"
     },
     "user_tz": 180
    },
    "id": "e63aaedc-83f1-4843-a47b-7fd402a4b31d",
    "outputId": "b4b20d6d-7563-4bf1-c690-c7c583ae077c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 23:17:45.488035: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-16 23:17:45.488087: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-16 23:17:45.488125: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-16 23:17:45.497526: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow not install, you could not use those pipelines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from eeg import EEG\n",
    "from MyGAN import *\n",
    "from gan_input_functions import *\n",
    "from helper_functions import *\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# torch.manual_seed(0) # Set for our testing purposes, please do not change!\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a2af7d-c1d1-45d4-8958-81d053d7031a",
   "metadata": {
    "id": "d7a2af7d-c1d1-45d4-8958-81d053d7031a"
   },
   "source": [
    "# Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "207d1fc1-361f-465d-a56d-7cf94ad860b9",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1697481806436,
     "user": {
      "displayName": "Larissa Rangel de Azevedo",
      "userId": "11239044081097926538"
     },
     "user_tz": 180
    },
    "id": "207d1fc1-361f-465d-a56d-7cf94ad860b9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n"
     ]
    }
   ],
   "source": [
    "eeg_data = EEG(subject_id=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d344cd-6063-4a15-beef-4fc2c618deb9",
   "metadata": {
    "id": "17d344cd-6063-4a15-beef-4fc2c618deb9"
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc7cafd0-c3aa-4aeb-b42e-450fe449d7e0",
   "metadata": {
    "id": "cc7cafd0-c3aa-4aeb-b42e-450fe449d7e0"
   },
   "outputs": [],
   "source": [
    "PATH = \"../Weights/Conv_Cond_Gan_v1/Gen_Weights.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29cfaf43-b0d8-418f-81ae-2f873cf9a3f2",
   "metadata": {
    "id": "29cfaf43-b0d8-418f-81ae-2f873cf9a3f2"
   },
   "outputs": [],
   "source": [
    "gen = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e6d5f2a-ce07-4c75-9359-3454d61591a4",
   "metadata": {
    "id": "6e6d5f2a-ce07-4c75-9359-3454d61591a4",
    "outputId": "a7506789-6d84-4d71-e260-d1d252c84100"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f02a035-99d4-411b-afce-b78333afd6e3",
   "metadata": {
    "id": "0f02a035-99d4-411b-afce-b78333afd6e3"
   },
   "source": [
    "## Generate Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e774492-34e5-4bdd-87fb-4fffb7b03f53",
   "metadata": {
    "id": "4e774492-34e5-4bdd-87fb-4fffb7b03f53"
   },
   "outputs": [],
   "source": [
    "n_epochs = 500\n",
    "z_dim = 64\n",
    "display_step = 500\n",
    "batch_size = 128\n",
    "lr = 0.00002\n",
    "n_classes = 4\n",
    "device = 'cuda'\n",
    "\n",
    "\n",
    "def generate_samples_with_labels(label, n_samples, generator, z_dim = 64, channel = None, extra_dim = True):\n",
    "    '''\n",
    "    Function for generating samples, once the generator has been trained\n",
    "        label: label of the movement to be sampled. See dictionary below\n",
    "        {'feet': 0, 'left_hand': 1, 'right_hand': 2, 'tongue': 3}\n",
    "        n_samples: number of samples to be generated\n",
    "        channel: electrode {'C3': 0, 'Cz': 1, 'C4': 2} -> Default: All channels\n",
    "        generator: the trained generator\n",
    "    '''\n",
    "\n",
    "    n_classes = 4\n",
    "\n",
    "    if channel == None:\n",
    "        noise_4_gen = get_noise(n_samples, z_dim)\n",
    "        label = get_one_hot_labels(torch.Tensor([label]).long(), n_classes).repeat(n_samples,1)\n",
    "\n",
    "        noise_and_labels = combine_vectors(noise_4_gen, label)\n",
    "        fake = generator(noise_and_labels)\n",
    "\n",
    "        if extra_dim == False:\n",
    "            fake = fake.reshape((fake.shape[0], fake.shape[2], fake.shape[3]))\n",
    "        return fake\n",
    "    else:\n",
    "        noise_4_gen = get_noise(n_samples, z_dim)\n",
    "        label = get_one_hot_labels(torch.Tensor([label]).long(), n_classes).repeat(n_samples,1)\n",
    "\n",
    "        noise_and_labels = combine_vectors(noise_4_gen, label)\n",
    "        fake = generator(noise_and_labels)\n",
    "        filtered_channel_fake = torch.select(fake, dim = 2, index = channel)\n",
    "\n",
    "        if extra_dim == False:\n",
    "            filtered_channel_fake = filtered_channel_fake.reshape((filtered_channel_fake.shape[0], filtered_channel_fake.shape[2]))\n",
    "\n",
    "        return filtered_channel_fake\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ebc0c8-e621-4096-8982-3a4bd35d63b3",
   "metadata": {
    "id": "80ebc0c8-e621-4096-8982-3a4bd35d63b3"
   },
   "source": [
    "## Filter Label and channels of real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3069eb5-02ae-4109-92f2-7ccd982b3acb",
   "metadata": {
    "id": "c3069eb5-02ae-4109-92f2-7ccd982b3acb"
   },
   "outputs": [],
   "source": [
    "def filter_label_and_channel(eeg_data, label, channel):\n",
    "    '''\n",
    "    Function to filter label and channel of original eeg data.\n",
    "        eeg_data: raw eeg data\n",
    "        label: class of movement\n",
    "        channel: electrode --   {'C3': 0, 'Cz': 1, 'C4': 2}\n",
    "    '''\n",
    "\n",
    "\n",
    "    mask = torch.where(eeg_data[:][1] == label, 1, 0)\n",
    "    filtered_eeg = eeg_data[:][0][torch.nonzero(mask).flatten()]\n",
    "    filtered_eeg = filtered_eeg.reshape((filtered_eeg.shape[0], filtered_eeg.shape[2], filtered_eeg.shape[3] ))\n",
    "    filtered_channel_eeg = torch.select(filtered_eeg, dim = 1, index = channel)\n",
    "\n",
    "    return filtered_channel_eeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b434da40-da1d-4b5e-a9b5-79e195c77c3b",
   "metadata": {
    "id": "b434da40-da1d-4b5e-a9b5-79e195c77c3b"
   },
   "source": [
    "## Classification Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d1eafe6-d073-4a4e-a92f-93aa26690224",
   "metadata": {
    "id": "2d1eafe6-d073-4a4e-a92f-93aa26690224"
   },
   "outputs": [],
   "source": [
    "def generate_samples_for_classification(n_samples, generator, z_dim = 64):\n",
    "    '''\n",
    "    Function for generating equal label samples for the classifier.\n",
    "        n_samples: number of samples to be generated\n",
    "        generator: the trained generator\n",
    "    '''\n",
    "    n_classes = 4\n",
    "\n",
    "    n_samples_partial = int(n_samples/n_classes)\n",
    "    noise_4_gen = get_noise(n_samples, z_dim)\n",
    "\n",
    "    label = [0,1,2,3]\n",
    "\n",
    "    label = [get_one_hot_labels(torch.Tensor([i]).long(), n_classes).repeat(n_samples_partial,1) for i in label]\n",
    "\n",
    "    label_concat = torch.zeros_like(torch.Tensor(0,4))\n",
    "    for i in range(len(label)):\n",
    "        label_concat = torch.cat((label_concat,label[i]), 0)\n",
    "\n",
    "    noise_and_labels = combine_vectors(noise_4_gen, label_concat)\n",
    "\n",
    "    fake = generator(noise_and_labels)\n",
    "\n",
    "    original_labels = torch.argmax(label_concat,dim = 1)\n",
    "    return (fake,original_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03b16c92-9229-4866-942a-00cf2cc586d1",
   "metadata": {
    "id": "03b16c92-9229-4866-942a-00cf2cc586d1",
    "outputId": "3724cb4d-7149-4ac4-b036-6df8626bc494"
   },
   "outputs": [],
   "source": [
    "def add_real_fake(real_eeg, fake_eeg):\n",
    "\n",
    "    real_data = real_eeg[:]\n",
    "    fake_data = fake_eeg\n",
    "\n",
    "    complete_eeg_data = torch.cat((real_data[0], fake_data[0]), dim = 0)\n",
    "    complete_label_data = torch.cat((real_data[1], fake_data[1]), dim = 0)\n",
    "\n",
    "    return (complete_eeg_data, complete_label_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab1bbca-f99e-4ea3-be04-a353d1122537",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "012c9671-b77c-480a-9ffb-9fca1ee5a541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1152, 1, 3, 400])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_data[:][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f99ff5f6-a862-4e97-be21-80e093c30e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import floor\n",
    "def compute_dim_Conv2D(Hin, \n",
    "                kernel_size=3, \n",
    "                stride=1,\n",
    "                padding = 0,\n",
    "                dilation = 1\n",
    "                ):\n",
    "    return floor( (Hin + (2*padding) - (dilation*(kernel_size-1)) -1)/(stride) + 1 ) \n",
    "\n",
    "def compute_dim_TransConv2D(Hin, \n",
    "                        kernel_size=118, \n",
    "                        stride=1,\n",
    "                        padding = 0,\n",
    "                        dilation = 1,\n",
    "                        output_padding = 0\n",
    "        \n",
    "        ):\n",
    "    return ((Hin - 1)*stride) - (2*padding)+ (dilation*(kernel_size - 1)) + output_padding + 1\n",
    "\n",
    "\n",
    "def compute_maxpool_2d(Hin, \n",
    "                        kernel_size=4, \n",
    "                        padding = 0,\n",
    "                        dilation = 1        \n",
    "        ):\n",
    "\n",
    "    stride = kernel_size\n",
    "    return ( ( (Hin + (2*padding)-(dilation*(kernel_size - 1)) -1) / stride ) + 1)\n",
    " \n",
    "\n",
    "compute_dim_Conv2D(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02737e3b-e82a-4ddf-aa9f-e70aa0e76264",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.T = 400\n",
    "\n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 400), padding = 0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16, False)\n",
    "        self.tconv2d1 = nn.ConvTranspose2d(16, 16, kernel_size = (118,1), stride = (1,1))\n",
    "        \n",
    "        # Layer 2\n",
    "        self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n",
    "        self.conv2 = nn.Conv2d(1, 4, (2, 2))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 1)\n",
    "\n",
    "        # # Layer 3\n",
    "        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n",
    "        self.conv3 = nn.Conv2d(4, 4, (8, 4))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling3 = nn.MaxPool2d(2, 1)\n",
    "\n",
    "        # # # FC Layer\n",
    "        # # # NOTE: This dimension will depend on the number of timestamps per sample in your data.\n",
    "        # # # I have 120 timepoints.\n",
    "        self.fc1 = nn.Linear(4*14*33, 4)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Layer 1\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Layer 2\n",
    "        x = self.padding1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling2(x)\n",
    "\n",
    "        # Layer 3\n",
    "        x = self.padding2(x)\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling3(x)\n",
    "\n",
    "        # FC Layer\n",
    "        x = x.reshape(-1, 4*14*33)\n",
    "        x = F.softmax(self.fc1(x), dim = 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03cf4506-d151-4b8c-9c09-55f9dfa08b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data\n",
    "X_train_eeg = eeg_data[:][0].to(torch.float32)\n",
    "y_train_eeg = eeg_data[:][1].to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "367be6a1-560b-41c7-8f11-92d42e8fcf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "classif = Classifier().cuda(0)\n",
    "criterion = nn.BCELoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classif.parameters())\n",
    "\n",
    "# input = Variable(X_train_eeg[0:10]).cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fYXOTGHks4Z-",
   "metadata": {
    "id": "fYXOTGHks4Z-"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, X, Y, params = [\"acc\"]):\n",
    "    results = []\n",
    "    batch_size = 100\n",
    "\n",
    "    predicted = []\n",
    "\n",
    "    for i in range(int(len(X)/batch_size)):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "\n",
    "        inputs = Variable(torch.from_numpy(X[s:e]).cuda(0))\n",
    "        pred = model(inputs)\n",
    "\n",
    "        predicted.append(pred.data.cpu().numpy())\n",
    "\n",
    "\n",
    "    inputs = Variable(torch.from_numpy(X).cuda(0))\n",
    "    predicted = model(inputs)\n",
    "\n",
    "    predicted = predicted.data.cpu().numpy()\n",
    "\n",
    "    for param in params:\n",
    "        if param == 'acc':\n",
    "            results.append(accuracy_score(Y, np.round(predicted)))\n",
    "        if param == \"auc\":\n",
    "            results.append(roc_auc_score(Y, predicted))\n",
    "        if param == \"recall\":\n",
    "            results.append(recall_score(Y, np.round(predicted)))\n",
    "        if param == \"precision\":\n",
    "            results.append(precision_score(Y, np.round(predicted)))\n",
    "        if param == \"fmeasure\":\n",
    "            precision = precision_score(Y, np.round(predicted))\n",
    "            recall = recall_score(Y, np.round(predicted))\n",
    "            results.append(2*precision*recall/ (precision+recall))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "Ha_pIpDGuDij",
   "metadata": {
    "id": "Ha_pIpDGuDij"
   },
   "outputs": [],
   "source": [
    "# X_train = np.random.rand(100, 1, 120, 64).astype('float32') # np.random.rand generates between [0, 1)\n",
    "# y_train = np.round(np.random.rand(100).astype('float32')) # binary data, so we round it to 0 or 1.\n",
    "\n",
    "# X_val = np.random.rand(100, 1, 120, 64).astype('float32')\n",
    "# y_val = np.round(np.random.rand(100).astype('float32'))\n",
    "\n",
    "# X_test = np.random.rand(100, 1, 120, 64).astype('float32')\n",
    "# y_test = np.round(np.random.rand(100).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b739553e-46e4-49bc-8abe-ea47bfe0a8bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(np\u001b[38;5;241m.\u001b[39marray([y_train_eeg[s:e]\u001b[38;5;241m.\u001b[39mnumpy()])\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# labels = torch.Tensor(labels.flatten())\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# # wrap them in Variable\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m Variable(\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m), Variable(labels\u001b[38;5;241m.\u001b[39mcuda(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# # zero the parameter gradients\u001b[39;00m\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    # print (\"\\nEpoch \", epoch)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i in range(int(len(X_train_eeg)/batch_size-1)):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = torch.from_numpy(X_train_eeg[s:e].numpy())\n",
    "        labels = torch.FloatTensor(np.array([y_train_eeg[s:e].numpy()]).T*1.0)\n",
    "        # labels = torch.Tensor(labels.flatten())\n",
    "        \n",
    "        # # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.cuda(0)), Variable(labels.cuda(0))\n",
    "\n",
    "        # # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = classif(inputs)\n",
    "        outputs = torch.argmax(outputs, dim = 1).to(torch.float32)\n",
    "        outputs = outputs.reshape((-1,1))\n",
    "        \n",
    "        # loss = criterion(outputs, labels)\n",
    "        # loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t8YSdfSeuIcJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1017,
     "status": "ok",
     "timestamp": 1697481494355,
     "user": {
      "displayName": "Larissa Rangel de Azevedo",
      "userId": "11239044081097926538"
     },
     "user_tz": 180
    },
    "id": "t8YSdfSeuIcJ",
    "outputId": "14ff20cf-f85b-4fce-a608-82cade025fd6"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    print (\"\\nEpoch \", epoch)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i in range(int(len(X_train)/batch_size-1)):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "\n",
    "        inputs = torch.from_numpy(X_train[s:e])\n",
    "        labels = torch.FloatTensor(np.array([y_train[s:e]]).T*1.0)\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.cuda(0)), Variable(labels.cuda(0))\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Validation accuracy\n",
    "    params = [\"acc\", \"auc\", \"fmeasure\"]\n",
    "    print (params)\n",
    "    print (\"Training Loss \", running_loss)\n",
    "    print (\"Train - \", evaluate(net, X_train, y_train, params))\n",
    "    print (\"Validation - \", evaluate(net, X_val, y_val, params))\n",
    "    print (\"Test - \", evaluate(net, X_test, y_test, params))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
